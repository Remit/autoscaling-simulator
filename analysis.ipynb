{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [16:16,  6.15it/s]                                                                                              \n"
     ]
    }
   ],
   "source": [
    "from autoscalingsim import simulator\n",
    "import pandas as pd\n",
    "\n",
    "starting_time = pd.Timestamp(\"2020-09-17T10:00:00\")\n",
    "simulation_step = pd.Timedelta(100, unit = 'ms')\n",
    "time_to_simulate = pd.Timedelta(10, unit = 'm')\n",
    "config_dir = \"experiments/short-experiment/holtwinters\"\n",
    "#\"experiments/short-experiment/reactive-mapping\"#\"experiments/testazuremanual2\"#\"experiments/test\"#\n",
    "results_dir = None\n",
    "\n",
    "simulator = simulator.Simulator(simulation_step, starting_time, time_to_simulate, 666)\n",
    "\n",
    "simulator.add_simulation(config_dir, results_dir)\n",
    "\n",
    "simulator.start_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stethoscope.analytical_engine import AnalysisFramework\n",
    "\n",
    "af = AnalysisFramework(simulation_step, 'D:/AutoscalingSim/results/test/short_oscillating/holtwinters')\n",
    "af.build_figures_for_single_simulation(simulator.simulations['holtwinters'], '')#af.build_figures_for_single_simulation(simulator.simulations['test'], '')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_ground.trainer import Trainer\n",
    "\n",
    "t = Trainer(\"training_conf/mapping-sgd/load\")\n",
    "t.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xxx = tf.keras.models.load_model('D:/@TUM/PhD/FINAL/experimentresults/models/nn/service-75c4ce5c-4da4-11eb-b901-d8cb8af1e959/eu/group1/dav_model.mdl')\n",
    "in_data = [[3., 1., 0.18705613], [3., 0., 0.17934185]]\n",
    "xxx.predict(tf.constant(in_data, dtype=tf.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import pickle\n",
    "\n",
    "\n",
    "model_config = {   \"loss\": \"squared_loss\",\n",
    "                   \"penalty\": \"l2\",\n",
    "                   \"alpha\": 0.0001,\n",
    "                   \"l1_ratio\": 0.15,\n",
    "                   \"tol\": 0.001,\n",
    "                   \"validation_fraction\": 0.1,\n",
    "                   \"n_iter_no_change\": 5,\n",
    "                   \"epsilon\": 0.1 }\n",
    "\n",
    "sgd_model = SGDRegressor(**model_config)\n",
    "\n",
    "def formatter_function(cur_aspect_val, cur_metrics_vals):\n",
    "\n",
    "    joint_vals = [[ val for val in cur_aspect_val ] if isinstance(cur_aspect_val, collections.Iterable) else [cur_aspect_val]]\n",
    "    for metric_vals in cur_metrics_vals.values():\n",
    "        joint_vals.append([ val for val in metric_vals ] if isinstance(metric_vals, collections.Iterable) else [metric_vals] )\n",
    "\n",
    "    return np.asarray(joint_vals).T\n",
    "\n",
    "cur_aspect_val = [1,2]\n",
    "cur_metrics_vals = {'load': [10, 20], 'wt': [133, 122]}\n",
    "X_train = formatter_function(cur_aspect_val, cur_metrics_vals)\n",
    "y_train = np.asarray([1200, 1100])\n",
    "print(X_train)\n",
    "sgd_model.partial_fit(X_train, y_train)\n",
    "\n",
    "X_test = formatter_function(1, {'load': 11, 'wt': 100})\n",
    "print(X_test)\n",
    "sgd_model.predict(X_test)\n",
    "\n",
    "pickle.dump( sgd_model, open( \"save.p\", \"wb\" ) )\n",
    "\n",
    "x = pickle.load( open( \"save.p\", \"rb\" ) )\n",
    "x.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimentgenerator.experiment_generator import ExperimentGenerator\n",
    "a = ExperimentGenerator('experiments/testazure3')\n",
    "a.generate_experiment('experiment_recipes/azure.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autoscalingsim.simevaluator.evaluation_framework import SimulationQualityEvaluationFramework\n",
    "\n",
    "sqef = SimulationQualityEvaluationFramework('experiments/testevaluation/evaluator_conf.json')\n",
    "sqef.create_simulations()\n",
    "sqef.simulate()\n",
    "sqef.build_figures('D:/AutoscalingSim/results/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To profile:\n",
    "# python -m cProfile -o D:\\AutoscalingSim\\results\\profiling_res.txt autoscalingsim-cl.py --step 10 --start \"2020-09-17T10:00:00\" --confdir \"experiments/test\" --simtime 1m\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "p = pstats.Stats('D://AutoscalingSim//results//profiling_res.txt')\n",
    "p.strip_dirs().sort_stats(SortKey.CALLS).print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cruncher.cruncher import Cruncher\n",
    "\n",
    "c = Cruncher('cruncher_conf/forecasting_experiment/oscillating_load/')\n",
    "c.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "idx = pd.date_range(pd.Timestamp(1000, unit = 'ms'), pd.Timestamp(20000, unit = 'ms'), freq = pd.Timedelta(1000, unit = 'ms'))\n",
    "\n",
    "x = pd.DataFrame({'datetime': idx, 'value': random.choices(range(10000), k = len(idx))}).set_index('datetime')\n",
    "x.shift(-15).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing pattern in load\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "interval_percentage = 6 / (5 * 60) # 6 seconds\n",
    "step_rps = 3 / (5 * 60 / 6)\n",
    "vals = []\n",
    "for request_rate in np.arange(0, 3.00, step_rps):\n",
    "    vals.append({ \"requests_count_level\": round(request_rate, 2), \"percentage_of_interval\": interval_percentage })\n",
    "    \n",
    "json.dumps(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoscalingsim import simulator\n",
    "import pandas as pd\n",
    "import collections\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "simulation_steps_ms = [10,20,30,40,50,60,70,80,90,100]\n",
    "starting_time = pd.Timestamp(\"2020-09-17T10:00:00\")\n",
    "time_to_simulate = pd.Timedelta(10, unit = 'm')\n",
    "repeats = 10\n",
    "\n",
    "results = collections.defaultdict(list)\n",
    "for sim_step_raw in simulation_steps_ms:\n",
    "    print(f'current simulation step is {sim_step_raw} ms')\n",
    "    for _ in range(repeats):\n",
    "        start = time.time()\n",
    "        simulation_step = pd.Timedelta(sim_step_raw, unit = 'ms')\n",
    "        config_dir = \"experiments/testazuremanual2\"\n",
    "        results_dir = None\n",
    "\n",
    "        sim = simulator.Simulator(simulation_step, starting_time, time_to_simulate)\n",
    "\n",
    "        sim.add_simulation(config_dir, results_dir)\n",
    "\n",
    "        sim.start_simulation()\n",
    "        \n",
    "        results[sim_step_raw].append(time.time() - start)\n",
    "        \n",
    "pickle.dump( results, open( \"performance_test_results_raw.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "res = pickle.load( open( \"performance_test_results_raw.pickle\", \"rb\" ) )\n",
    "\n",
    "results_means = [np.mean(times_per_simstep) / (10 * 60) for times_per_simstep in res.values()]\n",
    "results_stds = [np.std(times_per_simstep) / (10 * 60) for times_per_simstep in res.values()]\n",
    "steps = np.arange(10, 101, 10)\n",
    "\n",
    "p1 = plt.bar(steps, results_means, 7, yerr=results_stds)\n",
    "\n",
    "plt.ylabel('Wall clock time per 1 simulated second, s')\n",
    "plt.xlabel('Simulation step, ms')\n",
    "plt.xticks(steps)\n",
    "plt.yticks(np.arange(0.0, 2.0, 0.1))\n",
    "plt.hlines(0.5, xmin = 5, xmax = 105, colors = 'r', linestyles = 'dashed')\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"./performance_results.png\", dpi = 600, bbox_inches='tight')\n",
    "\n",
    "# Diminishing returns:\n",
    "(10 * 60_000) / steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
