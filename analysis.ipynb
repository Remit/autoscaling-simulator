{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:03, 25.30it/s]                                                                                                \n"
     ]
    }
   ],
   "source": [
    "from autoscalingsim import simulator\n",
    "import pandas as pd\n",
    "\n",
    "starting_time = pd.Timestamp(\"2020-09-17T10:00:00\")\n",
    "simulation_step = pd.Timedelta(10, unit = 'ms')\n",
    "time_to_simulate_days = 0.00001#0.005\n",
    "config_dir = \"experiments/test\"\n",
    "results_dir = None\n",
    "\n",
    "simulator = simulator.Simulator(simulation_step,\n",
    "                                starting_time,\n",
    "                                time_to_simulate_days)\n",
    "\n",
    "simulator.add_simulation(config_dir,\n",
    "                         results_dir)\n",
    "\n",
    "simulator.start_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdJElEQVR4nO3de7hVdb3v8fcHWIVsMRXWQQRsUWF5CbwsDUV3bHcX9RiWkunZZKnF1m646+k5truY7Uue6tjZ2sWHksq22cnrYbdBi7RCE3VBUgmm6EZZyVbERBTYseR7/hhj2mQy11pjLtaYc7DG5/U882GOy5zzw5iwvmuM32/8fooIzMysvIa1OoCZmbWWC4GZWcm5EJiZlZwLgZlZybkQmJmVnAuBmVnJjWh1gEaNHTs2Ojo6Wh3DzGyPsnz58mcior3etj2uEHR0dNDV1dXqGGZmexRJj/e2zZeGzMxKzoXAzKzkXAjMzErOhcDMrORyKwSSRkq6T9JKSQ9KuqzOPpJ0paQ1kn4j6ai88piZWX159hr6L+CkiHhBUhtwl6TFEbGsap9TgCnp403AN9M/zcysSXI7I4jEC+liW/qoHfP6dODadN9lwL6SxueVyczMdpVrG4Gk4ZIeAJ4GfhoR99bsMgFYV7Xcna6rfZ+5krokdW3YsCG/wGZmJZRrIYiIlyLiCGAicKykw2t2Ub2X1Xmf+RHRGRGd7e11b4wzM7MBakqvoYh4Dvg5cHLNpm5gUtXyRODJZmQyM7NEnr2G2iXtmz7fC3gL8FDNbguBc9PeQ9OBTRGxPq9MZma2qzx7DY0HvidpOEnB+VFE/FjShQARcTWwCDgVWANsAc7LMY+ZmdWRWyGIiN8AR9ZZf3XV8wA+nFcGMzPrn+8sNjMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzksutEEiaJOlOSaslPShpXp19ZkraJOmB9PG5vPKYmVl9I3J87x7gExGxQtJoYLmkn0bEqpr9lkbEaTnmMDOzPuR2RhAR6yNiRfp8M7AamJDX55mZ2cA0pY1AUgdwJHBvnc3HSVopabGkw3p5/VxJXZK6NmzYkGNSM7Pyyb0QSNobuAm4OCKer9m8Anh1REwDrgJurfceETE/IjojorO9vT3fwGZmJZNrIZDURlIErouIm2u3R8TzEfFC+nwR0CZpbJ6ZzMxsZ3n2GhJwDbA6Iq7oZZ8D0v2QdGyaZ2NemczMbFd59hqaAbwX+K2kB9J1fw8cBBARVwOzgYsk9QBbgbMjInLMZGZmNXIrBBFxF6B+9vka8LW8MpiZWf98Z7GZWcm5EJiZlZwLgZlZybkQmJmVnAuBmVnJuRCYmZWcC4GZWcm5EJiZlVy/hUDSPEn7KHGNpBWS3taMcGZmlr8sZwTnp6OGvg1oB84DLs81lZmZNU2WQlAZJuJU4DsRsZJ+ho4wM7M9R5ZCsFzST0gKwe3ptJM78o1lZmbNkmXQuQuAI4DHImKLpDEkl4fMzGwI6LcQRMQOkpnEKssb8ZwBZmZDhruPmpmVnAuBmVnJNVQIJO2fVxAzM2uNXguBpM9UPT9U0sMkPYjWSnpTU9KZmVnu+jojOKPq+ZeBeRExGTgL+GquqczMrGmyXho6MCIWA0TEfcBe+UUyM7Nm6qv76GskLSS5i3iipFERsSXd1pZ/NDMza4a+CsHpNcvDACSNA76ZWyIzM2uqXgtBRPyil/VPAV/PLZGZmTWV7yMwMyu53AqBpEmS7pS0WtKDkubV2UeSrpS0RtJvJB2VVx4zM6uvz0Igabikvxvge/cAn4iIQ4DpwIclHVqzzynAlPQxF7c9mJk1XZ+FICJeYtdG40wiYn1ErEifbwZWAxNqdjsduDYSy4B9JY0fyOeZmdnAZBmG+m5JXwP+L/BiZWXlh3wWkjqAI4F7azZNANZVLXen69bXvH4uyRkDBx10UNaPNTOzDLIUguPTP79QtS6Ak7J8gKS9gZuAi9MpL3faXOclscuKiPnAfIDOzs5dtpuZ2cBlmY/grwb65pLaSIrAdRFxc51duoFJVcsTgScH+nlmZta4fnsNSRon6RpJi9PlQyVdkOF1Aq4BVkfEFb3sthA4N+09NB3YFBHre9nXzMxykKX76HeB24ED0+WHgYszvG4G8F7gJEkPpI9TJV0o6cJ0n0XAY8Aa4FvAhxoJb2Zmuy9LG8HYiPiRpE8BRESPpJf6e1FE3EX9NoDqfQL4cKakZmaWiyxnBC+mE9YHQOUSTq6pzMysabKcEXyc5Fr+ayXdDbQDs3NNZWZmTZOl19AKSW8GXk9yqef3EbE992RmZtYU/RYCSSNJGnFPILk8tFTS1RGxLe9wZmaWvyyXhq4FNgNXpcvnAN8H3p1XKDMza54sheD1ETGtavlOSSvzCmRmZs2VpdfQr9OeQgBIehNwd36RzMysmbKcEbyJ5O7fJ9Llg4DVkn5LcivA1NzSmZlZ7rIUgpNzT2FmZi2Tpfvo480IYmZmreE5i83MSs6FwMys5LIMQ/0Xkoalzw+WNCudZ8DMzIaALGcEvwRGSpoA/Aw4j2RoajMzGwKyFAJFxBbgDOCqiHgXcGi+sczMrFkyFQJJxwF/A/x7ui5Lt1MzM9sDZCkE84BPAbdExIOSXgPcmW8sMzNrliy/2Y+LiFmVhYh4TNLSHDOZmVkTZTkj+FTGdWZmtgfq9YxA0inAqcAESVdWbdoH6Mk7mJmZNUdfl4aeBLqAWcDyqvWbgb/LM5SZmTVPr4UgIlYCKyX9oDI1paT9gEkR8cdmBTQzs3xlaSP4qaR9JO0PrAS+I+mKnHOZmVmTZCkEr4qI50luKPtORBwNvCXfWGZm1ixZCsEISeOBs4AfZ31jSQskPS3pd71snylpk6QH0sfnsr63mZkNniyF4AvA7cCjEXF/ekPZIxle9136n9RmaUQckT6+kOE9zcxskGWZmOYG4Iaq5ceAMzO87peSOnYnnJmZ5S/LMNQHS/pZ5RKPpKmSPjNIn3+cpJWSFks6rI8McyV1SerasGHDIH20mZlBtktD3yK5k3g7QET8Bjh7ED57BfDqiJgGXAXc2tuOETE/IjojorO9vX0QPtrMzCqyFIJREXFfzbrdvrM4Ip6PiBfS54uANkljd/d9zcysMVkKwTOSXgsEgKTZwPrd/WBJB0hS+vzYNMvG3X1fMzNrTJbRRz8MzAfeIOkPwH8Ac/p7kaTrgZnAWEndwKVAG0BEXA3MBi6S1ANsBc6OiBjIX8LMzAYuS6+hx4C3SPoLYFhEbM7yxhFxTj/bvwZ8LVNKMzPLTb+FoPZGr/RqDu73b2Y2NGS5NPRi1fORwGnA6nzimJlZs2W5NPS/q5clfQVYmFsiMzNrqiy9hmqNAl4z2EHMzKw1srQR/Ja06ygwHGgnGX/IzMyGgCxtBKdVPe8BnooIT1VpZjZEZCkEtd1F96n0HAKIiGcHNZGZmTVVlkKwApgE/BEQsC/wRLotcHuBmdkeLUtj8W3AOyJibESMIblUdHNETI4IFwEzsz1clkJwTDooHAARsRh4c36RzMysmbJcGnomnX/gX0kuBc3Bg8OZmQ0ZWc4IziHpMnpL+mhP15mZ2RCQ5c7iZ4F5kvauzB9gZmZDR5apKo+XtApYlS5Pk/SN3JOZmVlTZLk09FXg7aTtAhGxEvjLPEOZmVnzZBprKCLW1ax6KYcsZmbWAll6Da2TdDwQkl4BfAwPQ21mNmRkOSO4kGS6yglAN3BEumxmZkNAn2cEkoYD/yci/qZJeczMrMn6PCOIiJeA9vSSkJmZDUFZ2gjWAndLWkjVtJURcUVeoczMrHmyFIIn08cwYHS+cczMrNmy3Fl8WTOCmJlZawxkzmIzMxtCcisEkhZIelrS73rZLklXSloj6TeSjsori5mZ9S7PM4LvAif3sf0UYEr6mAt8M8csZmbWi4YLgaQPSXqPpD7bFyLil0Bf8xmfDlwbiWXAvpLGN5rHzMx2z0DOCAScANy8m589Aagew6g7XbfrB0pzJXVJ6tqwYcNufqyZmVXL0n10JxHx9UH6bNV7+14+cz4wH6Czs7PuPmZmNjC9FgJJH+/rhYNwQ1k3MKlqeSLJ/QpmZtZEfV0aGp0+OoGLSC7bTCAZhO7QQfjshcC5ae+h6cCmiFg/CO9rZmYN6PWMoHIjmaSfAEdFxOZ0+fPADf29saTrgZnAWEndwKVAW/reVwOLgFOBNcAW4Lzd+HuYmdkAZWkjOAj4U9Xyn4CO/l4UEX1OcB8RgYezNjNruSyF4PvAfZJuIWnMfRdwba6pzMysabKMNfRPkm4j6TIKcF5E/DrfWGZm1iyZuo9GxHJJ64CRAJIOiognck1mZmZN0e8NZZJmSXoE+A/gF+mfi/MOZmZmzZHlzuJ/AKYDD0fEZOAtwN25pjIzs6bJUgi2R8RGYJikYRFxJ8kE9mZmNgRkaSN4TtLewFLgOklPAz35xjIzs2bJckZwOrAVuBi4DXgUeEeeoczMrHmydB99UdI44BhgI7A4vVRkZmZDQJZeQ2cB9wHvBs4C7pU0O+9gZmbWHFnaCD4NHBMRTwNIageWADfmGczMzJojSxvBsEoRSG3M+DozM9sDZDkjuE3S7cD16fJ7SEYONTOzISBLY/EnJZ0JzCCZVWx+RNySezIzM2uKrGMN3QTclHMWMzNrgb6mqtxM/TmERTKdwD65pTIzs6bpa4ay0c0MYmZmreHeP2ZmJedCYGZWci4EZmYl50JgZlZyLgRmZiXnQmBmVnIuBGZmJZdrIZB0sqTfS1oj6ZI622dK2iTpgfTxuTzzmJnZrjINMTEQkoYDXwfeCnQD90taGBGranZdGhGn5ZXDzMz6lucZwbHAmoh4LCL+BPyQZNpLMzMrkDwLwQRgXdVyd7qu1nGSVkpaLOmwem8kaa6kLkldGzZsyCOrmVlp5VkIVGdd7SB2K4BXR8Q04Crg1npvFBHzI6IzIjrb29sHOaaZWbnlWQi6gUlVyxOBJ6t3iIjnI+KF9PkioE3S2BwzmZlZjTwLwf3AFEmTJb0COBtYWL2DpAMkKX1+bJpnY46ZzMysRm69hiKiR9JHgNuB4cCCiHhQ0oXp9quB2cBFknqArcDZEVFvDgQzM8uJ9rSfu52dndHV1dXqGGa2h9m+fTvd3d1s27at1VFyNXLkSCZOnEhbW9tO6yUtj4jOeq/J7YzAzKxIuru7GT16NB0dHaRXpIeciGDjxo10d3czefLkzK/zEBNmVgrbtm1jzJgxQ7YIAEhizJgxDZ/1uBCYWWkM5SJQMZC/owuBmVnJuRCYmRXUrbfeyqpVfx6ebebMmeTRWcaFwMysoGoLQV5cCMzMmuid73wnRx99NIcddhjz588HYO+99355+4033sj73/9+fvWrX7Fw4UI++clPcsQRR/Doo48CcMMNN3Dsscdy8MEHs3Tp0kHJ5O6jZlY6l/3bg6x68vlBfc9DD9yHS99Rd9zMnSxYsID999+frVu3cswxx3DmmWfW3e/4449n1qxZnHbaacyePfvl9T09Pdx3330sWrSIyy67jCVLlux2dhcCM7MmuvLKK7nlllsAWLduHY888khDrz/jjDMAOProo1m7du2gZHIhMLPSyfKbex5+/vOfs2TJEu655x5GjRrFzJkz2bZt205dPvu7B+CVr3wlAMOHD6enp2dQcrmNwMysSTZt2sR+++3HqFGjeOihh1i2bBkA48aNY/Xq1ezYsePlswWA0aNHs3nz5txzuRCYmTXJySefTE9PD1OnTuWzn/0s06dPB+Dyyy/ntNNO46STTmL8+PEv73/22Wfz5S9/mSOPPPLlxuI8eNA5MyuF1atXc8ghh7Q6RlPU+7v2NeiczwjMzErOhcDMrORcCMzMSs6FwMys5FwIzMxKzoXAzKzkXAjMzJpk7dq1HH744a2OsQsXAjOzknMhMDNrop6eHt73vvcxdepUZs+ezZYtW+jo6OCZZ54BoKuri5kzZ7Jjxw6mTJnChg0bANixYweve93rXt5vMHnQOTMrn8WXwH/+dnDf84A3wimX97vb73//e6655hpmzJjB+eefzze+8Y26+w0bNow5c+Zw3XXXcfHFF7NkyRKmTZvG2LFjBzc3PiMwM2uqSZMmMWPGDADmzJnDXXfd1eu+559/Ptdeey2QzGNw3nnn5ZIp1zMCSScD/wIMB74dEZfXbFe6/VRgC/D+iFiRZyYzsyy/ueelesjpyvKIESPYsWMHsPMw1JMmTWLcuHHccccd3HvvvVx33XW5ZMrtjEDScODrwCnAocA5kg6t2e0UYEr6mAt8M688ZmZF8MQTT3DPPfcAcP3113PCCSfQ0dHB8uXLAbjpppt22v8DH/gAc+bM4ayzzmL48OG5ZMrz0tCxwJqIeCwi/gT8EDi9Zp/TgWsjsQzYV9L42jcyMxsqDjnkEL73ve8xdepUnn32WS666CIuvfRS5s2bx4knnrjLD/tZs2bxwgsv5HZZCPK9NDQBWFe13A28KcM+E4D11TtJmktyxsBBBx006EHNzJqho6ODVatW7bL+xBNP5OGHH677mpUrVzJt2jTe8IY35JYrzzMC1VlXO/lBln2IiPkR0RkRne3t7YMSzsys6C6//HLOPPNMvvjFL+b6OXkWgm5gUtXyRODJAexjZlZKl1xyCY8//jgnnHBCrp+TZyG4H5giabKkVwBnAwtr9lkInKvEdGBTRKyvfSMzs8Gwp83IOBAD+Tvm1kYQET2SPgLcTtJ9dEFEPCjpwnT71cAikq6ja0i6j+bXGmJmpTZy5Eg2btzImDFjdunCOVREBBs3bmTkyJENvc5zFptZKWzfvp3u7u6d+ukPRSNHjmTixIm0tbXttL6vOYs9xISZlUJbWxuTJ09udYxC8hATZmYl50JgZlZyLgRmZiW3xzUWS9oAPN7qHDXGAoM/SPjuc67GFDUXFDNbETNVFDFbqzO9OiLq3pG7xxWCIpLU1VtrfCs5V2OKmguKma2ImSqKmK2ImSp8acjMrORcCMzMSs6FYHDMb3WAXjhXY4qaC4qZrYiZKoqYrYiZALcRmJmVns8IzMxKzoXAzKzkXAhKQEN1qMUc+Zg1xserMUU7Xm4jMDMrOZ8RDHGSLpH02vR5oX4LKSofs8b4eDWmiMfLhWCQSBol6cB0NrbabS05zpKmAf8M/E9Jr48Cnf4V8Xiln13IY+bj1Rgfr8b40tAgkXQ5yfzLi4GHgbXAs+lMbSNIjvX2Jmf6EsnscE8Cc4ArgOvTTMMiYkcz89RkK9zxSnMV8pj5eDWcy8erkVwuBIND0h+AfwN2AKNI/uGtBn4GXArsiIh5Tc60Ajg5Ip6WdC7wLuCGiPhBM3PUU8TjleYq5DHz8Wo4l49XIyLCj918APsBf0vyD07A8cCngWuBK4GNwLFNznQE8O2adWcAXcD3gdf4eO0Zx8zHy8cr74fPCAaJpNHA1ojoqVn/98AHI6Jpc+SlDVDDgP0jYoOkEZVcksaRXKNcGxH/0KxMdTIW5niln1voY+bj1XA+H68GeM7iwTMcGAM8VbN+HfCtZgaJpLq/JOklSeMi4qmqbU9JugLYv5mZ6ijM8YI94pj5eDXGx6sBPiPYTZJmAOeli3sB/wXcDvx7RLwgaR+S30ya1jBVlSlITo93ytSsHP1kg4Icr5pchTpmPl4DzgU+Xpm5EOwmSUuBHwAPAVuAaUAn8DTw5YjYVLBMX4mI55qdKWO2lhyvDLladsx8vAY1l49Xb1rVODEUHsCrgF8DI6rW7QUcBnwPuAx4RcEyfb7ZmYp8vIp8zHy8fLyalrGVHz4UHsAngUXAm2vWjwXubdE/vMJlKno253KuMuaqPHxpaDdJGglcDPwV8ALwW2AJ8FZgekS83ZmKn825nKuMuSpcCAaJpEkk1/yOIflyf0DSEPSwM+2qqNmcy7lKmcuFYPdJUkSEpAkAEfEHZ+pdUbM5V2OcqzFFzQUedG7A0htEKn9WBraqnPq1ZFTBImaqKGq2ouaqMTz907l6UfM9Vu6Pcq6MfEYwSNIv9Cng8Ih4utV5oJiZKqqyvTGqbq5ptaLkkjQ8Il6qWbcemNbK77Kouepxrux8Z/EASDqCZGTDySQ3iNwZEb+TNCuSwaSaPopgETNVZTsKmAJMJPkt8mcRsVzSf4/krsqWZCtqLoDKD1tJld+6Bbw3/S53+WFc5lySDgfeSHJGd2dEPKFkhFHnyshnBA1KW/8XAyuAR0juFtwMPAD8Y7TgxpAiZqrKthdwB7AKWAmMAw4F1gNXRsRDzrVTrlcCXwJujIildbbvHS24E7XAuSr/9p8GniEZVuITlevvkkZGxDbn6pvbCBo3B3gqIj4BLAC+TdIP+Dng06ozEUZJM1WcA2yKiAuAa4CvAJ8BHgU+Jmk/59rJ+cBHgQWS/iDpXyRNqdp+maS9netlc4DuiHgP8FngWeDcqu0fSou+c/XBhaBx/wlslTQ6Iv5EMuRtG8nogR3AdGfaya+B9ZI6IuLFiPhjRDwIfAMYCXzAuXYyHnh3REwBZpP8JnmvpF9L+hEwoxW/eRc410nArwAi4lngq8AsSR2S/hJ4a0Rsda6+uY2gcUuB9wK3KBnqdi3wTxGxQ1Ib8Drgl870st+RnJncpmS8lf8HLI6IrZLaSc5cnOvPvgnsn3Y1vAe4B0DSicAvgAucaydfIv05lmZ7RNKPgbkk7WU3OFf/3EYwQJKmknyh96QNP5OAHwPHRcQWZ9ol22TgTOA4kga0h4BtwPta+ZtRUXOl2V5BMpNWZdz6lRTjuyxqrhGRTPm4F3AzyZnw+FZfiy9qrmouBINE0sHACRGxoNVZKlqdSdLrgQ8CyyLixnTd3sA+JAVrWYt6cxQ51wUkhfyWmm0Hksyqdatz9Z6r0hNH0nkkl6uafomvqLn64kKQkaTXAR8C7gPujoh1LY5UyEwVko4muS56P/B2YE1EvLO1qfaYXG8DHnWu3lXl6iIZqsG5doMbi7P7NMkp3eHAZyV9XtKpkoZLepWkzzvTTs4FbouIT0TE4cBzkuYBSJoo6ULn6jXXG9NcH0tzHSjpQ85VN9fH6+SaIOki58rOhSC7EcDVwHXAT0hmGHoHSc+cO4CDnWknh5K0T1R8neQ3Skjuc+hseqLEnpSrMiLlBcBRTU+U2BNznQ8c3fREiaLm6pN7DWV3IcnEEpuA1ZLGkPTGmUByvbkVvSaKmKly89E/k3RpVSTul/S8pHOAE0nGZ3cu53KuAnAbQT8qX2gf22cAN0XEAWXOVPXZu2SrrEsbr1eQXDed5lzO5VzF4DOC/g2TNB2YSXJTzc0RcUfV9geA053pZcMkHQf8JXAgVdki4mFJl5LcZelczuVcBeEzgn5IOp/k2t6/AgcA/4NkvtEFJGPSbHSmTNm+A1xFMnH39kjugHYu53KuIogWzpO5JzyA24F31aw7iuSH7kecqaFsH02X5VzO5VzFebjXUB8kiaT3zU7X9SJiBfAp4D2SmtrLpIiZGsh2lqTOSP9XOJdzOVcxuBD0If3i5gOHSbpD0gf153HYRwH/DXiw7JmKns25nKuMuRrhNoI+SDqSpDvmcyTX/d5P0k/4LmArydDPTe0OVsRMRc/mXM5VxlyNcK+hXiiZvep/AS+RfJkPR8RfKxmZ8giSCr++7JmKns25nKuMuRrlS0O9u4BkWOKTgb8FXivp3RGxAVhGMp54s0+nipip6Nmcy7nKmKshLgS9O5I/TyzxNMkwDpU7dT9Ka26tL2KmiqJmcy7nKmOuhrgQ1JE29FwC/KGyLpLhZF9UMijZXwPfLXumomdzLucqY66BcGNxH/TnMcSHRTLb1xSSCak3RURLBo8qYqaiZ3Mu5ypjrka4sbgPkU5Okn65wyOZbu6HwFPOtKuiZnMu5ypjrkb4jKBBkoZB8qW3OktFETNVFDWbczXGuRpT1Fy9cSEwMys5NxabmZWcC4GZWcm5EJiZlZwLgZlZybkQmJmV3P8HBPxEGmb+0ngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autoscalingsim.analysis.analytical_engine import AnalysisFramework\n",
    "\n",
    "af = AnalysisFramework(simulation_step, 'D:/AutoscalingSim/results/test')\n",
    "af.build_figures(simulator.simulations['test'], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "_ = plt.bar(['auth','buy'], [4, 0], 0.7)\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3\n",
      "2: 2\n",
      "3: 1\n",
      "4: 2\n",
      "6: 1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-26fac31a0f79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter([1, 1, 2, 3, 4, 1, 2, 4, 6])\n",
    "for elem, count in counter.items():\n",
    "    print(\"{}: {}\".format(elem, count))\n",
    "    \n",
    "dd = collections.defaultdict(list)\n",
    "dd[1].append(1)\n",
    "dd\n",
    "\n",
    "Point = collections.namedtuple('Point', {'x', 'y'})\n",
    "r = Point(1 ,20)\n",
    "r.x\n",
    "\n",
    "a = (item for item in range(5))\n",
    "for item in a:\n",
    "    print(item)\n",
    "    \n",
    "def gen():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    \n",
    "g = gen()\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'half'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def cached(limit):\n",
    "    \n",
    "    def decorator(func):\n",
    "        cache = {}\n",
    "        \n",
    "        @wraps(func)\n",
    "        def new_func(x):\n",
    "            \n",
    "            if x not in cache:\n",
    "                if len(cache) == limit:\n",
    "                    del cache[list(cache.keys())[0]]\n",
    "                cache[x] = func(x)\n",
    "                print(cache)\n",
    "\n",
    "            return cache[x]\n",
    "\n",
    "        return new_func\n",
    "    \n",
    "    return decorator\n",
    "\n",
    "@cached(limit = 3)\n",
    "def half(x):\n",
    "    return x / 2\n",
    "\n",
    "half.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telegram\n"
     ]
    }
   ],
   "source": [
    "class Message:\n",
    "    \n",
    "    _REGISTRY = {}\n",
    "    \n",
    "    @classmethod\n",
    "    def register(cls, name):\n",
    "        def decorator(klass):\n",
    "            cls._REGISTRY[name] = klass\n",
    "            return klass\n",
    "        return decorator\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, message_type):\n",
    "        klass = cls._REGISTRY[message_type]\n",
    "        return klass()\n",
    "    \n",
    "@Message.register('telegram')\n",
    "class Telegram(Message):\n",
    "    def send(self):\n",
    "        print('telegram')\n",
    "        \n",
    "msg = Message.create('telegram')\n",
    "msg.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 and 7\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    \n",
    "    y = 6\n",
    "    \n",
    "    @classmethod\n",
    "    def new(cls, x):\n",
    "        u = cls()\n",
    "        u.x = x\n",
    "        return u\n",
    "    \n",
    "    def get_x(self):\n",
    "        return self.x\n",
    "    \n",
    "a = A.new(5)\n",
    "b = A.new(7)\n",
    "print(f\"{a.x} and {b.x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "x = pd.DataFrame({'datetime': [1,2,3], 'value': [4, 5, 6]}).set_index('datetime')\n",
    "x1 = pd.DataFrame(columns = [x.index.name] + x.columns.to_list()).set_index(x.index.name)\n",
    "converted_vals_marked = collections.defaultdict(list)\n",
    "converted_vals_marked.update((k, []) for k in ([x.index.name] + x.columns.to_list()))\n",
    "for ts, row in x.iterrows():\n",
    "    converted_vals = [A(row_elem) for row_elem in row]\n",
    "    for colname, val in zip(x.columns.to_list(), converted_vals):\n",
    "        converted_vals_marked[colname].append(val)\n",
    "    converted_vals_marked[x.index.name].append(ts)\n",
    "\n",
    "xx = pd.DataFrame(converted_vals_marked).set_index(x.index.name)\n",
    "    \n",
    "max(xx['value']).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "\n",
    "dd = {month: index for index, month in enumerate(calendar.month_abbr) if month}\n",
    "'Dec' in dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "25\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class A:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        return A(self.x * other)\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        if self.x > other.x:\n",
    "            return self\n",
    "        else:\n",
    "            return other\n",
    "\n",
    "df1 = pd.DataFrame(data = {'index': [1,2,3], 'val': [A(1), A(5), A(13)]})\n",
    "df1 = df1.set_index('index')\n",
    "df2 = df1 * 5\n",
    "\n",
    "for i, r in df2.iterrows():\n",
    "    print(r[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x, y = 0):\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        \n",
    "        return A(self.x + other.x)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return other + self.x\n",
    "        \n",
    "sum([A(2), A(4), A(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class A:\n",
    "    def __init__(self,\n",
    "                 x):\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "    def __deepcopy__(self, memo):\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            setattr(result, k, copy.deepcopy(v, memo))\n",
    "            \n",
    "        return result\n",
    "        \n",
    "a = A(9)\n",
    "b = copy.deepcopy(a)\n",
    "b.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B:\n",
    "    def __init__(self):\n",
    "        self.t = 5\n",
    "\n",
    "class A:\n",
    "    def __init__(self, x):\n",
    "        self._x = x\n",
    "        \n",
    "    def upd(self, x):\n",
    "        t = self\n",
    "        t.x = x\n",
    "        return self.x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return AI(self)\n",
    "\n",
    "class AI:\n",
    "    def __init__(self, a):\n",
    "        self._i = 0\n",
    "        self._a = a\n",
    "        \n",
    "    def __next__(self):\n",
    "        \n",
    "        if self._i < len(self._a._x):\n",
    "            ret = self._a._x[self._i]\n",
    "            self._i += 1\n",
    "            return ret\n",
    "        raise StopIteration\n",
    "    \n",
    "a = A([B(), B()])\n",
    "for aa in a:\n",
    "    aa.t = 6\n",
    "    \n",
    "b = {}.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int.__div__(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_inspect import get_parameters\n",
    "\n",
    "class A:\n",
    "    pass\n",
    "\n",
    "class B:\n",
    "    pass\n",
    "\n",
    "list_of_a = List[A]\n",
    "list_of_b = List[B]\n",
    "\n",
    "class D:\n",
    "    def __init__(self, x):\n",
    "        if x[0].__class__ == A:\n",
    "            self.t = 'A'\n",
    "        elif x[0].__class__ == B:\n",
    "            self.t = 'B'\n",
    "\n",
    "    \n",
    "d = D([A(), A()])\n",
    "d.t\n",
    "#ff = [B(), B()]\n",
    "#get_parameters(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from autoscalingsim.simulation.simulation import Simulation\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "CDF_FILENAME = 'cdf_response_times.png'\n",
    "RESP_TIMES_HIST_FILENAME = 'hist_response_times.png'\n",
    "FULFILLED_FAILED_BARS_FILENAME = 'bars_fulfilled_failed.png'\n",
    "\n",
    "TS_LINE_WORKLOAD_FILENAME = 'ts_line_workload.png'\n",
    "TOTAL_REQS_BARS_FILENAME = 'bars_total_gen_reqs.png'\n",
    "TS_LINE_NODES_FILENAME = 'ts_line_nodes.png'\n",
    "BUF_WAIT_TIME_HIST_FILENAME = 'hist_buf_waiting_time.png'\n",
    "REQ_TIMES_DISTR_BARS_FILENAME = 'bars_req_time_distribution_by_cat.png'\n",
    "\n",
    "MAX_PLOTS_CNT_ROW = 4\n",
    "\n",
    "class AnalysisFramework:\n",
    "    \"\"\"\n",
    "    Combines the functionality to build the figures based on the simulation\n",
    "    results. The following figures are supported:\n",
    "        - Autoscaling quality evaluation category:\n",
    "            + CDF of the response times, all the request types on the same plot\n",
    "            + Histogram of the response times, separately for each request type\n",
    "            + Barchart of fulfilled requests vs dropped, a bar for each request type\n",
    "            > utilization?\n",
    "        - Autoscaling behaviour characterization category:\n",
    "            + Line graph (x axis - time) of the generated requests count,\n",
    "              all the request types on the same plot\n",
    "            + Barchart of the overall amount of generated requests by type\n",
    "            + Line graph (x axis - time) of the desired/current node count,\n",
    "              separately for each node type\n",
    "            + Histogram of the waiting times in the service buffers,\n",
    "              separately for each buffer (idea - to locate the bottleneck service)\n",
    "            + Barchart of the processing vs waiting vs network time for the fulfilled requests,\n",
    "              a bar for each request type\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 simulation_step_ms,\n",
    "                 figures_dir = None):\n",
    "        \n",
    "        self.simulation_step_ms = simulation_step_ms\n",
    "        self.figures_dir = figures_dir\n",
    "        \n",
    "    def build_figures(self,\n",
    "                      simulation = None,\n",
    "                      results_dir = None,\n",
    "                      figures_dir = None):\n",
    "        # TODO: figure settings from config file?\n",
    "        # TODO: get results from the results_dir, also need to add storing into it\n",
    "        if simulation is None and results_dir is None:\n",
    "            sys.exit('Neither simulation nor results directory is provided, cannot build figures.')\n",
    "        \n",
    "        figures_dir_in_use = self.figures_dir\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figures_dir_in_use = figures_dir\n",
    "            \n",
    "        # Getting the data into the unified representation for processing\n",
    "        # either from the simulation or from the results_dir\n",
    "        response_times_per_request_type = {}\n",
    "        workload_ts_per_request_type = {}\n",
    "        buffer_times_by_request = {}\n",
    "        network_times_by_request = {}\n",
    "        desired_node_count = {}\n",
    "        actual_node_count = {}\n",
    "        if not simulation is None:      \n",
    "            workload_ts_per_request_type = simulation.workload_model.workload\n",
    "            response_times_per_request_type = simulation.application_model.response_times_by_request\n",
    "            buffer_times_by_request = simulation.application_model.buffer_times_by_request\n",
    "            network_times_by_request = simulation.application_model.network_times_by_request\n",
    "            desired_node_count = simulation.application_model.platform_model.compute_desired_node_count(self.simulation_step_ms,\n",
    "                                                                                                         simulation.time_to_simulate_ms)\n",
    "            actual_node_count = simulation.application_model.platform_model.compute_actual_node_count(self.simulation_step_ms,\n",
    "                                                                                                      simulation.time_to_simulate_ms)\n",
    "            \n",
    "        # Building figures with the internal functions\n",
    "        # Autoscaling quality evaluation category\n",
    "        self._resp_times_cdf(response_times_per_request_type,\n",
    "                             figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._resp_times_histogram(response_times_per_request_type,\n",
    "                                   3 * self.simulation_step_ms,\n",
    "                                   figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._fulfilled_dropped_barchart(response_times_per_request_type,\n",
    "                                         workload_ts_per_request_type,\n",
    "                                         figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        # Autoscaling behaviour characterization category\n",
    "        self._workload_line_graph(workload_ts_per_request_type,\n",
    "                                  resolution_ms = 5000,\n",
    "                                  figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._generated_requests_by_type_barchart(workload_ts_per_request_type,\n",
    "                                                  figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._nodes_usage_line_graph(desired_node_count,\n",
    "                                     actual_node_count,\n",
    "                                     figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._waiting_service_buffers_histogram(buffer_times_by_request,\n",
    "                                                bins_size_ms = 3 * self.simulation_step_ms,\n",
    "                                                figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._distribution_of_reqs_times_barchart(response_times_per_request_type,\n",
    "                                                  buffer_times_by_request,\n",
    "                                                  network_times_by_request,\n",
    "                                                  figures_dir = figures_dir_in_use)\n",
    "    \n",
    "    def _resp_times_cdf(self,\n",
    "                        response_times_per_request_type,\n",
    "                        figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds CDF of the requests by the response times, separate line for\n",
    "        each request type.\n",
    "        \"\"\"\n",
    "        \n",
    "        max_response_time = max([max(response_times_of_req) for response_times_of_req in response_times_per_request_type.values()])\n",
    "        cdf_xlim = max_response_time + 1 * self.simulation_step_ms + 1\n",
    "        x_axis = range(0, cdf_xlim, self.simulation_step_ms)\n",
    "        \n",
    "        cdfs_per_req_type = {}\n",
    "        for req_type, response_times in response_times_per_request_type.items():\n",
    "            reqs_count_binned = [0] * len(x_axis)\n",
    "            \n",
    "            for response_time in response_times:\n",
    "                reqs_count_binned[response_time // self.simulation_step_ms] += 1\n",
    "            \n",
    "            cdfs_per_req_type[req_type] = np.cumsum(reqs_count_binned) / sum(reqs_count_binned)\n",
    "        \n",
    "        for req_type, cdf_vals in cdfs_per_req_type.items():\n",
    "            plt.plot(x_axis, cdf_vals, label = req_type)\n",
    "        \n",
    "        percentiles = [0.99, 0.95, 0.90, 0.80, 0.50]\n",
    "        font = {'color':  'black',\n",
    "                'weight': 'normal',\n",
    "                'size': 8}\n",
    "        for percentile in percentiles:\n",
    "            plt.hlines(percentile, min(x_axis), max(x_axis),\n",
    "                       colors='k', linestyles='dashed', lw = 0.5)\n",
    "            plt.text(0, percentile + 0.001,\n",
    "                     \"{}th percentile\".format(int(percentile * 100)),\n",
    "                     fontdict = font)\n",
    "        \n",
    "        plt.xlabel('Response time, ms')\n",
    "        plt.legend(loc = \"lower right\")\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, CDF_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.title('CDF of requests by response time')\n",
    "            plt.show()\n",
    "            \n",
    "    def _resp_times_histogram(self,\n",
    "                              response_times_per_request_type,\n",
    "                              bins_size_ms = 10,\n",
    "                              figures_dir = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Builds histogram of requests by the response time.\n",
    "        \"\"\"\n",
    "        max_response_time = max([max(response_times_of_req) for response_times_of_req in response_times_per_request_type.values()])\n",
    "        bins_cnt = math.ceil(max_response_time / bins_size_ms)\n",
    "        \n",
    "        plots_count = len(response_times_per_request_type)\n",
    "        rows_cnt = 1\n",
    "        cols_cnt = plots_count\n",
    "        if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "            rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "        \n",
    "        fig, axs = plt.subplots(rows_cnt, cols_cnt,\n",
    "                                sharey = True, tight_layout = True)\n",
    "        \n",
    "        # Ref: https://stackoverflow.com/questions/6963035/pyplot-axes-labels-for-subplots/36542971#36542971\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        \n",
    "        i = 0\n",
    "        for req_type, response_times in response_times_per_request_type.items():\n",
    "            axs_adapted = axs\n",
    "            \n",
    "            if cols_cnt * rows_cnt > 1:\n",
    "                axs_adapted = axs[i]\n",
    "                i += 1\n",
    "                \n",
    "            axs_adapted.hist(response_times,\n",
    "                             bins = bins_cnt)\n",
    "            axs_adapted.title.set_text(req_type)\n",
    "            \n",
    "\n",
    "        plt.xlabel('Response time, ms')\n",
    "        plt.ylabel('Completed requests')\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, RESP_TIMES_HIST_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of requests by response time', y = 1.05)\n",
    "            plt.show()\n",
    "            \n",
    "    def _fulfilled_dropped_barchart(self,\n",
    "                                    response_times_per_request_type,\n",
    "                                    workload_ts_per_request_type,\n",
    "                                    bar_width = 0.15,\n",
    "                                    figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds a barchart of fulfilled requests vs dropped,\n",
    "        a bar for each request type.\n",
    "        \"\"\"\n",
    "        \n",
    "        req_types = list(workload_ts_per_request_type.keys())\n",
    "        succeeded_reqs = []\n",
    "        failed_reqs = []\n",
    "        max_req_cnt = 0\n",
    "        for req_type, workload_timeline in workload_ts_per_request_type.items():\n",
    "            responses_cnt = 0\n",
    "            if req_type in response_times_per_request_type:\n",
    "                responses_cnt = len(response_times_per_request_type[req_type])\n",
    "            \n",
    "            succeeded_reqs.append(responses_cnt)\n",
    "            \n",
    "            requests_cnt = 0\n",
    "            for _, cnt in workload_timeline:\n",
    "                requests_cnt += cnt\n",
    "                \n",
    "            failed_reqs_cnt = requests_cnt - responses_cnt\n",
    "            failed_reqs.append(failed_reqs_cnt)\n",
    "            \n",
    "            max_req_cnt = max([max_req_cnt, requests_cnt])\n",
    "                \n",
    "        plt.bar(req_types, succeeded_reqs,\n",
    "                bar_width, label='Fulfilled')\n",
    "        plt.bar(req_types, failed_reqs,\n",
    "                bar_width, bottom = succeeded_reqs, label='Failed')\n",
    "\n",
    "        plt.ylabel('Requests count')\n",
    "        plt.ylim(top = int(max_req_cnt * 1.05))\n",
    "        plt.legend()\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, FULFILLED_FAILED_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Fulfilled and failed requests')\n",
    "            plt.show()\n",
    "    \n",
    "    def _workload_line_graph(self,\n",
    "                             workload_ts_per_request_type,\n",
    "                             resolution_ms = 1000,\n",
    "                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Line graph (x axis - time) of the desired/current node count,\n",
    "        separately for each node type\n",
    "        \"\"\"\n",
    "        for req_type, workload_ts_raw in workload_ts_per_request_type.items():\n",
    "            \n",
    "            workload_ts_times_ms = []\n",
    "            workload_ts_req_counts = []\n",
    "            new_frame_start_ms = workload_ts_raw[0][0] + resolution_ms\n",
    "            cur_req_cnt = 0\n",
    "            last_added = False\n",
    "            for workload_obs in workload_ts_raw:\n",
    "                last_added = False\n",
    "                \n",
    "                cur_ts_ms = workload_obs[0]\n",
    "                reqs_cnt = workload_obs[1]\n",
    "                \n",
    "                if cur_ts_ms > new_frame_start_ms:\n",
    "                    workload_ts_times_ms.append(new_frame_start_ms)\n",
    "                    workload_ts_req_counts.append(cur_req_cnt)\n",
    "                    cur_req_cnt = 0\n",
    "                    new_frame_start_ms = cur_ts_ms + resolution_ms\n",
    "                    last_added = True\n",
    "                    \n",
    "                cur_req_cnt += reqs_cnt\n",
    "            \n",
    "            if not last_added:\n",
    "                workload_ts_times_ms.append(new_frame_start_ms)\n",
    "                workload_ts_req_counts.append(cur_req_cnt)\n",
    "                \n",
    "            workload_ts_time = [datetime.fromtimestamp(workload_ts_time_ms // 1000) for workload_ts_time_ms in workload_ts_times_ms]\n",
    "\n",
    "            df_workload = pd.DataFrame(data = {'time': workload_ts_time,\n",
    "                                               'requests': workload_ts_req_counts})\n",
    "            df_workload = df_workload.set_index('time')\n",
    "            plt.plot(df_workload, label = req_type)\n",
    "            \n",
    "            plt.ylabel('Workload, requests per {} s'.format(resolution_ms // 1000))\n",
    "            plt.legend(loc = \"lower right\")\n",
    "            plt.xticks(rotation = 70)\n",
    "            \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TS_LINE_WORKLOAD_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.title('Generated workload over time')\n",
    "            plt.show()\n",
    "    \n",
    "    def _generated_requests_by_type_barchart(self,\n",
    "                                             workload_ts_per_request_type,\n",
    "                                             bar_width = 0.15,\n",
    "                                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Barchart of the overall amount of generated requests by type.\n",
    "        \"\"\"\n",
    "        \n",
    "        req_types = list(workload_ts_per_request_type.keys())\n",
    "        reqs_cnts = {}\n",
    "        max_req_cnt = 0\n",
    "        for req_type, workload_timeline in workload_ts_per_request_type.items():\n",
    "            \n",
    "            requests_cnt = 0\n",
    "            for _, cnt in workload_timeline:\n",
    "                requests_cnt += cnt\n",
    "                \n",
    "            reqs_cnts[req_type] = requests_cnt\n",
    "            \n",
    "            max_req_cnt = max([max_req_cnt, requests_cnt])\n",
    "        \n",
    "        plt.bar(list(reqs_cnts.keys()), list(reqs_cnts.values()),\n",
    "                bar_width)\n",
    "\n",
    "        plt.ylabel('Requests count')\n",
    "        plt.ylim(top = int(max_req_cnt * 1.05))\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TOTAL_REQS_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Total generated requests by type')\n",
    "            plt.show()\n",
    "    \n",
    "    def _nodes_usage_line_graph(self,\n",
    "                                desired_node_count,\n",
    "                                actual_node_count,\n",
    "                                resolution_ms = 5000,\n",
    "                                figures_dir = None):\n",
    "        \"\"\"\n",
    "        Line graph (x axis - time) of the desired/current node count,\n",
    "        separately for each node type\n",
    "        \"\"\"\n",
    "        \n",
    "        node_types = list(desired_node_count.keys())\n",
    "        plots_count = len(node_types)\n",
    "        rows_cnt = 1\n",
    "        cols_cnt = plots_count\n",
    "        if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "            rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "        \n",
    "        fig, axs = plt.subplots(rows_cnt, cols_cnt,\n",
    "                                sharey = True, tight_layout = True)\n",
    "        \n",
    "        # Ref: https://stackoverflow.com/questions/6963035/pyplot-axes-labels-for-subplots/36542971#36542971\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        \n",
    "        for node_type in node_types:\n",
    "            \n",
    "            desired_ts = desired_node_count[node_type]['timestamps']\n",
    "            desired_count = desired_node_count[node_type]['count']\n",
    "            \n",
    "            actual_ts = []\n",
    "            actual_count = []\n",
    "            if node_type in actual_node_count:\n",
    "                actual_ts = actual_node_count[node_type]['timestamps']\n",
    "                actual_count = actual_node_count[node_type]['count']\n",
    "            \n",
    "                \n",
    "            desired_ts_time = [datetime.fromtimestamp(desired_ts_el // 1000) for desired_ts_el in desired_ts]\n",
    "            actual_ts_time = [datetime.fromtimestamp(actual_ts_el // 1000) for actual_ts_el in actual_ts]\n",
    "\n",
    "            df_desired = pd.DataFrame(data = {'time': desired_ts_time,\n",
    "                                              'nodes': desired_count})\n",
    "            df_actual = pd.DataFrame(data = {'time': actual_ts_time,\n",
    "                                             'nodes': actual_count})\n",
    "            df_desired = df_desired.set_index('time')\n",
    "            df_actual = df_actual.set_index('time')\n",
    "            \n",
    "            axs.title.set_text(\"Node type {}\".format(node_type))\n",
    "            axs.plot(df_desired, label = \"Desired count\")\n",
    "            axs.plot(df_actual, label = \"Actual count\")\n",
    "            \n",
    "            fig.canvas.draw()\n",
    "            axs.set_xticklabels([txt.get_text() for txt in axs.get_xticklabels()], rotation = 70)\n",
    "            \n",
    "        plt.ylabel('Nodes')\n",
    "        axs.legend(loc = 'upper right', bbox_to_anchor=(0.9, -0.1), ncol = 2,\n",
    "                   borderaxespad = 4.0)\n",
    "            \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TS_LINE_NODES_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Desired and actual number of nodes per node type', y = 1.05)\n",
    "            plt.show()\n",
    "    \n",
    "    def _waiting_service_buffers_histogram(self,\n",
    "                                           buffer_times_by_request,\n",
    "                                           bins_size_ms = 10,\n",
    "                                           figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds a set of histograms for the waiting times in buffers.\n",
    "        \"\"\"\n",
    "        \n",
    "        outer_rows_cnt = len(buffer_times_by_request)\n",
    "        outer_cols_cnt = 1\n",
    "        fig = plt.figure()#figsize=(10, 8))\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        outer = gridspec.GridSpec(outer_rows_cnt, outer_cols_cnt,\n",
    "                                  wspace=0.2, hspace=1.0)\n",
    "        \n",
    "        font = {'color':  'black',\n",
    "                'weight': 'bold',\n",
    "                'size': 12}\n",
    "        \n",
    "        i = 0\n",
    "        for req_type, buffers_waiting_times_raw in buffer_times_by_request.items():\n",
    "            \n",
    "            ax_out = plt.Subplot(fig, outer[i])\n",
    "            ax_out.set_title('Request type {}'.format(req_type),\n",
    "                             y = 1.2,\n",
    "                             fontdict = font)\n",
    "            \n",
    "            ax_out.set_xlabel('Time spent waiting in the buffer, ms')\n",
    "            ax_out.set_ylabel('Waiting requests')\n",
    "            ax_out.xaxis.labelpad = 25\n",
    "            ax_out.yaxis.labelpad = 15\n",
    "            ax_out.set_xticks([])\n",
    "            #ax_out.set_yticks([])\n",
    "            \n",
    "            fig.add_subplot(ax_out)\n",
    "            \n",
    "            buffers_waiting_times = {}\n",
    "            for buffer_waiting_time_raw in buffers_waiting_times_raw:\n",
    "                service_name = list(buffer_waiting_time_raw.keys())[0]\n",
    "                buffer_waiting_time_for_service = list(buffer_waiting_time_raw.values())[0]\n",
    "                \n",
    "                if service_name in buffers_waiting_times:\n",
    "                    buffers_waiting_times[service_name].append(buffer_waiting_time_for_service)\n",
    "                else:\n",
    "                    buffers_waiting_times[service_name] = [buffer_waiting_time_for_service]\n",
    "            \n",
    "            max_waiting_time = max([max(sublist) for sublist in list(buffers_waiting_times.values())])\n",
    "            bins_cnt = math.ceil(max_waiting_time / bins_size_ms)\n",
    "            \n",
    "            plots_count = len(buffers_waiting_times)\n",
    "            rows_cnt = 1\n",
    "            cols_cnt = plots_count\n",
    "            if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "                rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "                \n",
    "            # Plotting for req type\n",
    "            inner = gridspec.GridSpecFromSubplotSpec(rows_cnt,\n",
    "                                                     cols_cnt,\n",
    "                                                     subplot_spec = outer[i],\n",
    "                                                     wspace = 0.5,\n",
    "                                                     hspace = 0.1)\n",
    "            \n",
    "            j = 0\n",
    "            for service_name, service_buffer_waiting_times in buffers_waiting_times.items():\n",
    "                ax = plt.Subplot(fig, inner[j], sharey = ax_out)\n",
    "                \n",
    "                ax.hist(service_buffer_waiting_times,\n",
    "                        bins = bins_cnt)\n",
    "                ax.title.set_text('Buffers of the {} service'.format(service_name))\n",
    "                \n",
    "                \n",
    "                if not ax.is_last_row():\n",
    "                    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "                plt.setp(ax.get_yticklabels(), visible=False)\n",
    "                \n",
    "                fig.add_subplot(ax)              \n",
    "                    \n",
    "                j += 1\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, BUF_WAIT_TIME_HIST_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of requests by buffer waiting time', y = 1.05)\n",
    "            plt.show()\n",
    "            \n",
    "    def _distribution_of_reqs_times_barchart(self,\n",
    "                                             response_times_per_request_type,\n",
    "                                             buffer_times_by_request,\n",
    "                                             network_times_by_request,\n",
    "                                             aggregation_fn = np.mean,\n",
    "                                             bar_width = 0.15,\n",
    "                                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Barchart of the processing vs waiting vs network time\n",
    "        for the fulfilled requests, a bar for each request type\n",
    "        \"\"\"\n",
    "        if not callable(aggregation_fn):\n",
    "            sys.exit('The aggregation function object is not callable.')\n",
    "        \n",
    "        aggregated_processing_time_per_req_type = []\n",
    "        aggregated_buf_waiting_time_per_req_type = []\n",
    "        aggregated_network_time_per_req_type = []\n",
    "        \n",
    "        req_types = list(response_times_per_request_type.keys())\n",
    "        for req_type in req_types:\n",
    "            \n",
    "            req_type_response_times = response_times_per_request_type[req_type]\n",
    "            \n",
    "            req_type_network_times = [0.0]\n",
    "            if req_type in network_times_by_request:\n",
    "                req_type_network_times = network_times_by_request[req_type]\n",
    "            aggregated_network_time_per_req_type.append(aggregation_fn(req_type_network_times))\n",
    "                \n",
    "            req_type_buf_waiting_times = [0.0]\n",
    "            if req_type in buffer_times_by_request:\n",
    "                req_type_buf_waiting_times = [list(buf_wait_time.values())[0] for buf_wait_time in buffer_times_by_request[req_type]]\n",
    "            aggregated_buf_waiting_time_per_req_type.append(aggregation_fn(req_type_buf_waiting_times))\n",
    "            \n",
    "            agg_proc_time = aggregation_fn(req_type_response_times) - (aggregated_buf_waiting_time_per_req_type[-1] + aggregated_network_time_per_req_type[-1])\n",
    "            aggregated_processing_time_per_req_type.append(agg_proc_time)\n",
    "            \n",
    "        plt.bar(req_types, aggregated_processing_time_per_req_type,\n",
    "                bar_width, label='Processing')\n",
    "        plt.bar(req_types, aggregated_network_time_per_req_type,\n",
    "                bar_width, bottom = aggregated_processing_time_per_req_type,\n",
    "                label='Transferring')\n",
    "        \n",
    "        plt.bar(req_types, aggregated_buf_waiting_time_per_req_type,\n",
    "                bar_width, bottom = np.array(aggregated_processing_time_per_req_type) \\\n",
    "                                    + np.array(aggregated_network_time_per_req_type),\n",
    "                label='Waiting')\n",
    "        \n",
    "        plt.ylabel('Duration, ms')\n",
    "        plt.legend(loc = 'upper right', bbox_to_anchor=(0.9, -0.1), ncol = 3)\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, REQ_TIMES_DISTR_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of the request time in the application,\\\n",
    "            \\naggregated with the {} function'.format(aggregation_fn.__name__))\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_framework = AnalysisFramework(simulation_step_ms)\n",
    "analysis_framework.build_figures(simulator.simulations[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .forecasting import *\n",
    "\n",
    "class MetricDescription:\n",
    "    \"\"\"\n",
    "    Stores all the necessary information to create a scaling metric.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 metric_name,\n",
    "                 metric_source_in_entity,\n",
    "                 scaled_aspect_source,\n",
    "                 values_filer,\n",
    "                 values_aggregator,\n",
    "                 target_value,\n",
    "                 stabilizer,\n",
    "                 timing_type,\n",
    "                 forecaster,\n",
    "                 capacity_adaptation_type,\n",
    "                 priority,\n",
    "                 initial_max_limit,\n",
    "                 initial_min_limit,\n",
    "                 initial_entity_representation_in_metric):\n",
    "\n",
    "        self.metric_name = metric_name\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "        self.scaled_aspect_source = scaled_aspect_source\n",
    "        self.values_filter = values_filer\n",
    "        self.values_aggregator = values_aggregator\n",
    "        self.priority = priority\n",
    "        self.target_value = target_value\n",
    "        self.stabilizer = stabilizer\n",
    "        self.timing_type = timing_type\n",
    "        self.forecaster = forecaster\n",
    "        self.capacity_adaptation_type = capacity_adaptation_type\n",
    "\n",
    "        self.initial_max_limit = initial_max_limit\n",
    "        self.initial_min_limit = initial_min_limit\n",
    "        self.initial_entity_representation_in_metric = initial_entity_representation_in_metric\n",
    "\n",
    "    def convert_to_metric(self):\n",
    "\n",
    "        return ScalingMetric(self.metric_name,\n",
    "                             self.metric_source_in_entity,\n",
    "                             self.scaled_aspect_source,\n",
    "                             self.values_filer,\n",
    "                             self.values_aggregator,\n",
    "                             self.target_value,\n",
    "                             self.stabilizer,\n",
    "                             self.timing_type,\n",
    "                             self.forecaster,\n",
    "                             self.capacity_adaptation_type,\n",
    "                             self.priority,\n",
    "                             self.initial_max_limit,\n",
    "                             self.initial_min_limit,\n",
    "                             self.initial_entity_representation_in_metric)\n",
    "\n",
    "class ScalingMetric:\n",
    "    \"\"\"\n",
    "    Abstract description of a metric used to determine by how much should the\n",
    "    associated entity be scaled. For instance, the ScalingMetric could be the\n",
    "    CPU utilization. The associated ScaledEntity that contains the metric\n",
    "    could be the node (= VM).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 metric_name,\n",
    "                 metric_source_in_entity,\n",
    "                 scaled_aspect_source,\n",
    "                 values_filer,\n",
    "                 values_aggregator,\n",
    "                 target_value,\n",
    "                 stabilizer,\n",
    "                 timing_type,\n",
    "                 forecaster,\n",
    "                 capacity_adaptation_type,\n",
    "                 priority,\n",
    "                 max_limit,\n",
    "                 min_limit,\n",
    "                 entity_representation_in_metric):\n",
    "        # Static state\n",
    "\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "        # Information sources for metric-based scaling:\n",
    "        # a property of a particular entity instance (object) that\n",
    "        # stores the metric values.\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "\n",
    "        # source of the current value for the scaled aspect, i.e.\n",
    "        # the characteristic that *may directly be changed* as the\n",
    "        # result of the autoscaling process, e.g. entity instances count,\n",
    "        # entity size in terms of some resource (CPU shares)\n",
    "        self.scaled_aspect_source = scaled_aspect_source\n",
    "\n",
    "        # Metric values preprocessing:\n",
    "        # a filter that takes some of the metrics values depending\n",
    "        # on the criteria in it, e.g. takes only values for last 5 seconds.\n",
    "        # Should be callable.\n",
    "        # TODO: consider filter chains\n",
    "        self.values_filter = values_filer\n",
    "\n",
    "        # an aggregator applicable to the time series metrics values\n",
    "        # -- it aggregates metric values prior to the comparison\n",
    "        # against the target. Should be callable.\n",
    "        # TODO: consider values aggregators chains\n",
    "        self.values_aggregator = values_aggregator\n",
    "\n",
    "        # Scaling determinants:\n",
    "        # integer value that determines the position of the metric in the\n",
    "        # sequence of metrics used to scale the entity; the higher the priority\n",
    "        # the closer is the metric to the beginning of the sequence, e.g. if\n",
    "        # there are metrics CPU with the priority 15 and memory with the priority\n",
    "        # -5, then the sequential aggregation thereof results in first computing\n",
    "        # the scaling action based on the CPU utilization, and then using\n",
    "        # these results as limits for the computation based on memory.\n",
    "        self.priority = priority\n",
    "\n",
    "        # a target value of the metric; comparison of the filtered and\n",
    "        # aggregated value of the metric against the target may\n",
    "        # result in the scaling depending on whether the predicate allows\n",
    "        # this or that scaling action.\n",
    "        self.target_value = target_value\n",
    "\n",
    "        # used to stabilize scaling actions over time, e.g. if the scaling happens\n",
    "        # many times over a short period of time, various start-up and termination\n",
    "        # effects may severely impact the response time latency as well as other metrics\n",
    "        self.stabilizer = stabilizer\n",
    "\n",
    "        # either predictive or reactive; depending on the value\n",
    "        # either the real metric value or its forecast is used.\n",
    "        # The use of the \"predictive\" demands presence of the\n",
    "        # forecaster.\n",
    "        # TODO: forecaster initialization\n",
    "        self.timing_type = timing_type\n",
    "        self.forecaster = MetricForecaster()\n",
    "\n",
    "        # either continuous (for vertical scaling) or discrete (for\n",
    "        # horizontal scaling)\n",
    "        self.capacity_adaptation_type = capacity_adaptation_type\n",
    "\n",
    "        # Dynamic state\n",
    "\n",
    "        # current min-max limits on the post-scaling result for the\n",
    "        # aspect of the scaled entity (count of scaled entities in case of horizontal scaling\n",
    "        # or resource limits of scaled entities in case of vertical scaling)\n",
    "        self.limiter = Limiter(min_limit, max_limit)\n",
    "\n",
    "        # current representation of the entity in terms of metric, for instance\n",
    "        # if the entity is the node and the metric is CPU utilization, and the capacity adaptation type is discrete,\n",
    "        # then the representation may be 1 which means that 100 utilization translates\n",
    "        # into 1 node of the given type. This property sits in dynamic category since\n",
    "        # it might get changed during the predictive autoscaling over time with\n",
    "        # new information becoming available about how the entities react on the change\n",
    "        # in metric, e.g. if the metric is the requests per second and the entity is node,\n",
    "        # there is no universal correspondence for every app and every request type.\n",
    "        self.entity_representation_in_metric = entity_representation_in_metric\n",
    "\n",
    "    def compute_desired_state(self):\n",
    "        \"\"\"\n",
    "        Computes the desired state of the associated scaled entity (e.g. service)\n",
    "        according to this particular metric.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extracts available metric values in a form of pandas DataFrame\n",
    "        # with the datetime index. Can be a single value or a sequence of\n",
    "        # values (in this case, some metric history is incorporated)\n",
    "        metric_vals = self.metric_source_in_entity\n",
    "        if self.timing_type == 'predictive':\n",
    "            metric_vals = self.forecaster(cur_metric_vals)\n",
    "        \n",
    "        # Filtering raw metric values (e.g. by removing NA or some\n",
    "        # abnormal values, or by smoothing the signal) and aggregating\n",
    "        # these filtered values to produce the desired aggregated metric,\n",
    "        # e.g. by averaging with the sliding window of a particular length\n",
    "        filtered_metric_vals = self.values_filter(metric_vals)\n",
    "        aggregated_metric_vals = self.values_aggregator(filtered_metric_vals)\n",
    "        \n",
    "        # Computing how does metric value related to the target --\n",
    "        # the assumption is that the closer it is to the target value,\n",
    "        # the better the current state of the application/infrastructure\n",
    "        # reflects the needs of the scaled entity in terms of this metric.\n",
    "        # The computed ratio is used to calaculate the desired amount of the\n",
    "        # scaled aspect (e.g. CPU shares or service instances) by using\n",
    "        # the representation of the metric in terms of the scaled entity and\n",
    "        # the current amount of the scaled entity. Lastly, the computed\n",
    "        # desired amount of the scaled aspect is stabilized to avoid\n",
    "        # oscillations in it that may cause too much overhead when scaling.\n",
    "        metric_ratio = aggregated_metric_vals / self.target_value\n",
    "        desired_scaled_aspect = math.ceil(metric_ratio * self.entity_representation_in_metric * self.scaled_aspect_source)\n",
    "        desired_scaled_aspect_stabilized = self.stabilizer(desired_scaled_aspect)\n",
    "        \n",
    "        # Limiting the produced values of the desired scaled aspect\n",
    "        # such that it stays inside the given band. The limiting\n",
    "        # post-processing is useful if there is a strict limit\n",
    "        # on a particular scaled aspect (e.g. number of VM instances)\n",
    "        # or if the adjustments to the desired scaled aspect must proceed\n",
    "        # in a chained way using different metrics -> min/max limits\n",
    "        # then serve as a communication channel.\n",
    "        desired_scaled_aspect_stabilized_limited = self.limiter(desired_scaled_aspect_stabilized)\n",
    "\n",
    "        return desired_scaled_aspect_stabilized_limited\n",
    "    \n",
    "    def update_limits(self,\n",
    "                      new_min,\n",
    "                      new_max):\n",
    "        \n",
    "        if not limiter is None:\n",
    "            self.limiter.update_limits(new_min,\n",
    "                                       new_max)\n",
    "\n",
    "class MetricForecaster:\n",
    "    \"\"\"\n",
    "    Wraps the supporting forecasting logic that updates the forecasting model\n",
    "    and makes predictions for the defined forecasting horizon. Since the changes\n",
    "    that impact the metric value may occur often, it makes little sense\n",
    "    to forecast for the long term, hence, the extrapolations provided here\n",
    "    are deemed to be very short-sighted. \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 fhorizon_in_steps,\n",
    "                 metric_source_in_entity,\n",
    "                 forecasting_model_name = None,\n",
    "                 forecasting_model_params = None,\n",
    "                 resolution_ms = 10,\n",
    "                 history_data_buffer_size = 10):\n",
    "        \n",
    "        # Static State\n",
    "        self.fhorizon_in_steps = fhorizon_in_steps\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "        self.resolution_ms = resolution_ms\n",
    "        self.history_data_buffer_size = history_data_buffer_size\n",
    "        \n",
    "        # Dynamic State\n",
    "        if (forecasting_model_name in forecasting_model_registry) and (not forecasting_model_params is None):\n",
    "            self.model = forecasting_model_registry[forecasting_model_name](forecasting_model_params)\n",
    "        else:\n",
    "            self.model = None\n",
    "            \n",
    "        self.history_data_buffer = pd.DataFrame(columns=['value'])\n",
    "\n",
    "    def __call__(self,\n",
    "                 metric_vals):\n",
    "        \n",
    "        \"\"\"\n",
    "        If the forecasting model is not yet fit, then return the metric values\n",
    "        as is by default. Otherwise, the forecast is produced with the existing\n",
    "        model. In any case, an attempt to update the model is performed, in which\n",
    "        at least the historical data is extracted for the accumulation.\n",
    "        \"\"\"\n",
    "        \n",
    "        forecast = metric_vals\n",
    "        if not self.model is None:\n",
    "            forecast = self.model.predict(metric_vals,\n",
    "                                          self.fhorizon_in_steps,\n",
    "                                          self.resolution_ms)\n",
    "            \n",
    "            self._update()\n",
    "        \n",
    "        return forecast\n",
    "        \n",
    "    def _update(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes the available metric values from the self.metric_source_in_entity\n",
    "        until the internal buffer of size self.history_data_buffer_size is full,\n",
    "        then it fits the forecasting model to the collected data. The model is\n",
    "        afterwards updated on each new observation if there was no interrupt in\n",
    "        data acquisition (determined by the timestamps). \n",
    "        \"\"\"\n",
    "        \n",
    "        metric_vals = self.metric_source_in_entity        \n",
    "        self.history_data_buffer = self.history_data_buffer.append(metric_vals)\n",
    "        self.history_data_buffer = self.history_data_buffer.iloc[-self.history_data_buffer_size:,]\n",
    "        if self.history_data_buffer.shape[0] >= self.history_data_buffer_size:\n",
    "            self.model.fit(self.history_data_buffer)\n",
    "                 \n",
    "class Limiter:\n",
    "    \"\"\"\n",
    "    Defines hard and soft limits on the value. Hard limits are set on the\n",
    "    initialization from the configurations and are never changed thereafter.\n",
    "    Soft limits can be updated at any time, e.g. by the desired scaled aspect\n",
    "    values provided by the previous metrics in the chain. Both sets of limits\n",
    "    are applied to the values provided to the limiter on call to it.\n",
    "    \n",
    "    If the soft limits represent a time series, then they have to be applied\n",
    "    to the values that correspond in their timestamps. No alignment logic is\n",
    "    provided -- if the values are somehow misaligned then the min value of\n",
    "    the soft max is used instead of the soft max, and the max value of the\n",
    "    soft min is used instead of soft min.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 init_min,\n",
    "                 init_max):\n",
    "        \n",
    "        self.hard_min = init_min\n",
    "        self.hard_max = init_max\n",
    "        self.soft_min = init_min\n",
    "        self.soft_max = init_max\n",
    "\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        result = self._min_comparison(self.soft_min, values)\n",
    "        result = self._max_comparison(self.soft_max, result)\n",
    "        \n",
    "        result = self._min_comparison(self.hard_min, result)\n",
    "        result = self._max_comparison(self.hard_max, result)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "                \n",
    "    def _min_comparison(self,\n",
    "                        x_min,\n",
    "                        values):\n",
    "        \n",
    "        result = None\n",
    "        if isinstance(x_min, pd.DataFrame):\n",
    "            if (x_min.shape[0] != values.shape[0]) or (np.sum(x_min.index == values.index) < values.shape[0]):\n",
    "                new_min = x_min.max()[0]\n",
    "                result = values[values < new_min].fillna(new_min)\n",
    "            elif (x_min.shape[0] == values.shape[0]) and (np.sum(x_min.index == values.index) == values.shape[0]):\n",
    "                result = values[values < x_min].fillna(x_min)\n",
    "        else:\n",
    "            result = values[values < x_min].fillna(x_min)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def _max_comparison(self,\n",
    "                        x_max,\n",
    "                        values):\n",
    "        \n",
    "        result = None\n",
    "        if isinstance(x_max, pd.DataFrame):\n",
    "            if (x_max.shape[0] != values.shape[0]) or (np.sum(x_max.index == values.index) < values.shape[0]):\n",
    "                new_max = x_max.min()[0]\n",
    "                result = values[values > new_max].fillna(new_max)\n",
    "            elif (x_max.shape[0] == values.shape[0]) and (np.sum(x_max.index == values.index) == values.shape[0]):\n",
    "                result = values[values > x_max].fillna(x_max)\n",
    "        else:\n",
    "            result = values[values > x_max].fillna(x_max)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "                                \n",
    "    def update_limits(self,\n",
    "                      new_min,\n",
    "                      new_max):\n",
    "        \n",
    "        self.soft_min = new_min\n",
    "        self.soft_max = new_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "class ValuesFilter(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An interface for the values filter applied on the preprocessing step\n",
    "    to the raw metrics values.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class DefaultNA(ValuesFilter):\n",
    "    \n",
    "    \"\"\"\n",
    "    Substitutes all the NA values for the default value, e.g. 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'default_value'\n",
    "        if param_key in config:\n",
    "            self.default_value = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} filter.'.format(param_key, self.__class__.__name__))\n",
    "    \n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        return values.fillna(self.default_value)\n",
    "    \n",
    "value_filter_registry = {}\n",
    "value_filter_registry['defaultNA'] = DefaultNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class ValuesAggregator(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An interface to the time window-based aggregator of the metric values.\n",
    "    Basically, it recasts the metric to some particular resolution by\n",
    "    applying the aggregation in the time window, e.g. taking max or avg.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class AvgAggregator(ValuesAggregator):\n",
    "    \n",
    "    \"\"\"\n",
    "    Aggregates the metric time series by computing the average over the\n",
    "    time window of desired resolution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'resolution_window_ms'\n",
    "        if param_key in config:\n",
    "            self.resolution_window_ms = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} aggregator.'.format(param_key, self.__class__.__name__))\n",
    "\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        resolution_delta = self.resolution_window_ms * timedelta(microseconds = 1000)\n",
    "        window_start = values.index[0]\n",
    "        window_end = window_start + resolution_delta\n",
    "     \n",
    "        aggregated_vals = pd.DataFrame(columns=['datetime', 'value'])\n",
    "        aggregated_vals = aggregated_vals.set_index('datetime')\n",
    "        while window_start <= values.index[-1]:\n",
    "            \n",
    "            avg_val = values[(values.index >= window_start) & (values.index < window_end)].mean()[0]\n",
    "            data_to_add = {'datetime': [window_start],\n",
    "                           'value': [avg_val]}\n",
    "            df_to_add = pd.DataFrame(data_to_add)\n",
    "            df_to_add = df_to_add.set_index('datetime')\n",
    "            aggregated_vals = aggregated_vals.append(df_to_add)\n",
    "\n",
    "            window_start = window_end\n",
    "            window_end = window_start + resolution_delta\n",
    "            \n",
    "        return aggregated_vals\n",
    "    \n",
    "value_aggregator_registry = {}\n",
    "value_aggregator_registry['avgAggregator'] = AvgAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class Stabilizer(ABC):\n",
    "    \"\"\"\n",
    "    Defines how the scaled aspect is stabilized, i.e. tries to minimize the\n",
    "    oscillations in the scaled aspect using the windowing.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class MaxStabilizer(Stabilizer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Stabilizes the oscillations in the scaled aspect by substituting the values\n",
    "    in the time window for the max of the max value encountered in it and of the max\n",
    "    value found in the previous time window. Tends to overprovision the capacity.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'resolution_window_ms'\n",
    "        if param_key in config:\n",
    "            self.resolution_window_ms = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} stabilizer.'.format(param_key, self.__class__.__name__))\n",
    "    \n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        resolution_delta = self.resolution_window_ms * timedelta(microseconds = 1000)\n",
    "        window_start = values.index[0]\n",
    "        window_end = window_start + resolution_delta\n",
    "     \n",
    "        stabilized_vals = pd.DataFrame(columns=['datetime', 'value'])\n",
    "        stabilized_vals = stabilized_vals.set_index('datetime')\n",
    "        max_val = values.min()[0]\n",
    "        while window_start <= values.index[-1]:\n",
    "            \n",
    "            selected_vals = values[(values.index >= window_start) & (values.index < window_end)]\n",
    "            max_val = max([selected_vals.max()[0], max_val])\n",
    "            data_to_add = {'datetime': selected_vals.index,\n",
    "                           'value': [max_val] * selected_vals.shape[0]}\n",
    "            df_to_add = pd.DataFrame(data_to_add)\n",
    "            df_to_add = df_to_add.set_index('datetime')\n",
    "            stabilized_vals = stabilized_vals.append(df_to_add)\n",
    "\n",
    "            window_start = window_end\n",
    "            window_end = window_start + resolution_delta\n",
    "            \n",
    "        return stabilized_vals\n",
    "    \n",
    "value_stabilizer_registry = {}\n",
    "value_stabilizer_registry['maxStabilizer'] = MaxStabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class ForecastingModel(ABC):\n",
    "    \"\"\"\n",
    "    Wraps the forecasting model used by MetricForecaster.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 forecasting_model_params):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self,\n",
    "            data):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self,\n",
    "                metric_vals,\n",
    "                fhorizon_in_steps,\n",
    "                resolution_ms):\n",
    "        pass\n",
    "    \n",
    "class SimpleAverage(ForecastingModel):\n",
    "    \n",
    "    \"\"\"\n",
    "    The forecasting model that averages the last averaging_interval observations\n",
    "    and repeats the resulting averaged value as the forecast for the forecasting\n",
    "    horizon.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 forecasting_model_params):\n",
    "        \n",
    "        param_key = 'averaging_interval'\n",
    "        if param_key in forecasting_model_params:\n",
    "            self.averaging_interval = forecasting_model_params['averaging_interval']\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the forecasting model.'.format(param_key))\n",
    "        \n",
    "        self.averaged_value = 0\n",
    "    \n",
    "    def fit(self,\n",
    "            data):\n",
    "        \n",
    "        self.averaged_value = data.mean()[0]\n",
    "    \n",
    "    def predict(self,\n",
    "                metric_vals,\n",
    "                fhorizon_in_steps,\n",
    "                resolution_ms):\n",
    "        \n",
    "        one_ms = timedelta(microseconds=1000)\n",
    "        forecasting_interval_start = df.iloc[-1:,].index[0] + resolution_ms * one_ms\n",
    "        forecasting_interval_end = forecasting_interval_start + fhorizon_in_steps * resolution_ms * one_ms\n",
    "        forecast_interval = pd.date_range(start = forecasting_interval_start,\n",
    "                                          end = forecasting_interval_end,\n",
    "                                          freq = str(resolution_ms) + 'L')\n",
    "        forecasts_df = pd.DataFrame(date_rng, columns=['date'])\n",
    "        forecasts_df['value'] = [self.averaged_value] * len(date_rng)\n",
    "        forecasts_df['datetime'] = pd.to_datetime(forecasts_df['date'])\n",
    "        forecasts_df = forecasts_df.set_index('datetime')\n",
    "        forecasts_df.drop(['date'], axis=1, inplace=True)\n",
    "        \n",
    "        return forecasts_df\n",
    "    \n",
    "forecasting_model_registry = {}\n",
    "forecasting_model_registry['simpleAvg'] = SimpleAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "date_rng = pd.date_range(start='1/1/2018', end='1/02/2018', freq='H')\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['data'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "df.head(15)\n",
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('datetime')\n",
    "df.drop(['date'], axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.DataFrame(columns=['datetime', 'value'])\n",
    "tt = tt.set_index('datetime')\n",
    "data = {'datetime': [df.index[0]],\n",
    "        'value': [99]}\n",
    "t = pd.DataFrame(data)\n",
    "t = t.set_index('datetime')\n",
    "tt = tt.append(t)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "d = timedelta(microseconds=1000)\n",
    "df.iloc[-1:,].index[0] + 1000 * d\n",
    "\n",
    "date_rng = pd.date_range(start=df.iloc[-1:,].index[0] + 1000 * d,\n",
    "                         end=df.iloc[-1:,].index[0] + 10000 * d,\n",
    "                         freq = '1000L')\n",
    "\n",
    "df1 = pd.DataFrame(date_rng, columns=['date'])\n",
    "df1['value'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "df1['datetime'] = pd.to_datetime(df1['date'])\n",
    "df1 = df1.set_index('datetime')\n",
    "df1.drop(['date'], axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fparams = {}\n",
    "fparams['averaging_interval'] = 10\n",
    "mf = MetricForecaster(10,\n",
    "                      df1,\n",
    "                      'simpleAvg',\n",
    "                      fparams,\n",
    "                      1000,\n",
    "                      200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = mf(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = mf(df1)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = mf(df1)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = r.iloc[:50,].append(r1.iloc[50:,])\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr[(rr.index > rr.index[10]) & (rr.index < rr.index[9])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ScalingEffectAggregationRule(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An aggregation rule for the desired scaling effect values produced\n",
    "    by the metrics for the associated entity.\n",
    "    Two different approaches to aggregation are available:\n",
    "    \n",
    "        Sequential: the desired scaling effect is computed on a metric-by-metric\n",
    "                    basis starting with the metric of the highest priority, then\n",
    "                    the desired scaling effect computed for the previous metric is\n",
    "                    used as limits for the next metric to compute. The scaling\n",
    "                    effect produced by the last metric in the chain is used\n",
    "                    as the final desired scaling effect.\n",
    "                    \n",
    "        Parallel:   the desired scaling effect is computed at once, using the\n",
    "                    desired scaling effects computed by every metric. For instance,\n",
    "                    it can be an average of all the desired scaling effects,\n",
    "                    or the maximum can be taken.\n",
    "                    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        self.metrics_by_priority = metrics_by_priority\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self):\n",
    "        pass\n",
    "    \n",
    "class SequentialScalingEffectAggregationRule(ScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Sequentially calls metrics to produce desired scaling effect values for the\n",
    "    associated entity, each subsequent metric gets the soft limits on the desired\n",
    "    scaling effect values from the previous one (if it is not the first metric\n",
    "    in the sequence).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority,\n",
    "                 expected_deviation_ratio = 0.25):\n",
    "        \n",
    "        super().__init__(metrics_by_priority)\n",
    "        \n",
    "        if expected_deviation_ratio < 0:\n",
    "            raise ValueError('expected_deviation_ratio cannot be negative')\n",
    "        self.expected_deviation_ratio = expected_deviation_ratio\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        ordered_metrics = list(self.metrics_by_priority.values())\n",
    "        if len(ordered_metrics) > 1:\n",
    "            for metric, metric_next in zip(ordered_metrics[:-1], ordered_metrics[1:]):\n",
    "                desired_scaled_aspect = metric()\n",
    "                min_lim = np.floor((1 - self.expected_deviation_ratio) * desired_scaled_aspect)\n",
    "                max_lim = np.ceil((1 + self.expected_deviation_ratio) * desired_scaled_aspect)\n",
    "                metric_next.update_limits(min_lim, max_lim)\n",
    "                \n",
    "        return ordered_metrics[-1]()\n",
    "    \n",
    "class ParallelScalingEffectAggregationRule(ScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calls all the metrics at once and jointly aggregates their results.\n",
    "    Currently empty, but might be extended with some joint logic of the\n",
    "    derived concrete aggregation rules.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority,\n",
    "                 pairwise_operation):\n",
    "        \n",
    "        super().__init__(metrics_by_priority)\n",
    "        if not callable(pairwise_operation):\n",
    "            raise ValueError('pairwise_operation not callable.')\n",
    "        self.pairwise_operation = pairwise_operation\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        ordered_metrics = list(self.metrics_by_priority.values())\n",
    "        desired_scaled_aspect_result = ordered_metrics[0]()\n",
    "        if len(ordered_metrics) > 1:\n",
    "            # Pairwise iterative algorithm to account for possible\n",
    "            # inconsistencies in the time series.\n",
    "            \n",
    "            for metric in ordered_metrics[1:]:\n",
    "                \n",
    "                desired_scaled_aspect_result_new = pd.DataFrame(columns=['datetime', 'value'])\n",
    "                desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.set_index('datetime')\n",
    "                cur_desired_scaled_aspect = metric()\n",
    "                \n",
    "                i = 0\n",
    "                j = 0\n",
    "                while (i < len(desired_scaled_aspect_result.index)) and (j < len(cur_desired_scaled_aspect.index)):\n",
    "                    \n",
    "                    cur_res_index = desired_scaled_aspect_result.index[i]\n",
    "                    cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                    cur_val_1 = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index == cur_index]['value'][0]\n",
    "                    cur_val_2 = desired_scaled_aspect_result[desired_scaled_aspect_result.index == cur_res_index]['value'][0]\n",
    "                    aggregated_val = self.pairwise_operation(cur_val_1, cur_val_2)\n",
    "                    \n",
    "                    # Augments to the non-pairwise case\n",
    "                    while ((j + 1) < len(cur_desired_scaled_aspect.index)) and (cur_desired_scaled_aspect.index[j + 1] <= cur_res_index):\n",
    "                        j += 1\n",
    "                        cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                        cur_val_add = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index == cur_index]['value'][0]\n",
    "                        aggregated_val = self.pairwise_operation(aggregated_val, cur_val_add)\n",
    "                        \n",
    "                    data_to_add = {'datetime': [cur_res_index],\n",
    "                                   'value': [aggregated_val]}\n",
    "                    df_to_add = pd.DataFrame(data_to_add)\n",
    "                    df_to_add = df_to_add.set_index('datetime')\n",
    "                    desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.append(df_to_add)\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                    \n",
    "                # Finalizing with cur_index > cur_res_index / non-pairwise case\n",
    "                if j < len(cur_desired_scaled_aspect.index):\n",
    "                    cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                    df_to_add = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index >= cur_index]\n",
    "                    desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.append(df_to_add)\n",
    "                \n",
    "                desired_scaled_aspect_result = desired_scaled_aspect_result_new\n",
    "                            \n",
    "        return desired_scaled_aspect_result\n",
    "        \n",
    "class MaxScalingEffectAggregationRule(ParallelScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    maxScale - pairwise aggregation by taking the max value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        super().__init__(metrics_by_priority,\n",
    "                         max)\n",
    "        \n",
    "class MinScalingEffectAggregationRule(ParallelScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    minScale - pairwise aggregation by taking the min value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        super().__init__(metrics_by_priority,\n",
    "                         min)\n",
    "        \n",
    "scaling_aggregation_rules_registry = {}\n",
    "scaling_aggregation_rules_registry['seqScale'] = SequentialScalingEffectAggregationRule\n",
    "scaling_aggregation_rules_registry['maxScale'] = MaxScalingEffectAggregationRule\n",
    "scaling_aggregation_rules_registry['minScale'] = MinScalingEffectAggregationRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "class A:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.data\n",
    "    \n",
    "    def update_limits(self, s1, s2):\n",
    "        return\n",
    "    \n",
    "a1 = A(rr)\n",
    "a2 = A(r)\n",
    "\n",
    "mbp = {1: a1, 2: a2}\n",
    "mbp_sorted = collections.OrderedDict(sorted(mbp.items()))\n",
    "agg_rule = MaxScalingEffectAggregationRule(mbp_sorted)\n",
    "agg_rule()\n",
    "\n",
    "agg_rule_1 = SequentialScalingEffectAggregationRule(mbp_sorted)\n",
    "agg_rule_1()\n",
    "# config & integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, next_in_kin):\n",
    "        self.next_in_kin = next_in_kin\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.next_in_kin.hi()\n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(self)\n",
    "        self.name = name\n",
    "        \n",
    "    def hi(self):\n",
    "        print(\"Heyya from {}!\".format(self.name))\n",
    "        \n",
    "b = B(\"Buggy\")\n",
    "b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "class A(ABC):\n",
    "    tttt = 5\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def qq():\n",
    "        return A.tttt\n",
    "    \n",
    "A.qq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.__getattribute__('hi')()\n",
    "A.__getattribute__(A, 'qq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class D(C):\n",
    "    def __init__(self, par):\n",
    "        self._par = par\n",
    "        \n",
    "    @property\n",
    "    def par(self):\n",
    "        return self._par\n",
    "    \n",
    "    @par.setter\n",
    "    def par(self, nv):\n",
    "        self._par = nv\n",
    "        \n",
    "d = D(1)\n",
    "d.par = 3\n",
    "d.par\n",
    "d.__setattr__('par', 4)\n",
    "d.par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_rng = pd.date_range(start='1/1/2018', end='1/08/2018', freq='H')\n",
    "vals = [1] * len(date_rng)\n",
    "dff = pd.DataFrame(data = {'datetime': date_rng, 'val': vals})\n",
    "dff = dff.set_index('datetime')\n",
    "dff\n",
    "ddt = pd.Timedelta(120, unit = 'm')\n",
    "ddt\n",
    "len(dff[dff.index > dff.index[167]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "dd = {dff.index[1]: 12, dff.index[0]: 14}\n",
    "OrderedDict(sorted(dd.items(), key = lambda elem: elem[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "d = {'a': 1, 'b': 3, 't': 0}\n",
    "dd = OrderedDict(reversed(sorted(d.items(), key = lambda x: x[1])))\n",
    "\n",
    "poppy = ['a']\n",
    "poppy.append('c')\n",
    "poppy\n",
    "\n",
    "a = A()\n",
    "b = A()\n",
    "c = A()\n",
    "\n",
    "ttt = [a, b, c]\n",
    "print(ttt)\n",
    "ttt.remove(b)\n",
    "ttt\n",
    "{**{},**{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.copysign(1, -0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "b = {'a': 55, 'b': 9}\n",
    "\n",
    "all(v == 8 for v in a.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
