{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/43200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 10/43200 [00:00<32:35, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3E76BA8>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n",
      "scalingmetric\n",
      "{'eu': {'frontend': {'count': <autoscalingsim.utils.state.entity_state.scaling_aspects.Count object at 0x0000020AC3EA99B0>}}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EntitiesState' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-72643d65da7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                          results_dir)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_simulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\simulator.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[1;34m(self, simulation_name)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;31m# TODO: think about parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\simulation\\simulation.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_simulation_time\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulation_end\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_simulation_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulation_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim_round\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat_updates_every_round\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\simulation\\simulation.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplication_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_requests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_requests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         self.application_model.step(self.cur_simulation_time,\n\u001b[1;32m--> 130\u001b[1;33m                                     self.simulation_step)\n\u001b[0m",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\application\\application_model.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, cur_timestamp, simulation_step)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;31m# Calling scaling policy that determines the need to scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaling_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconcile_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_timestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     def enter_requests(self,\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\scaling\\policiesbuilder\\scaling_policy.py\u001b[0m in \u001b[0;36mreconcile_state\u001b[1;34m(self, cur_timestamp)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mdesired_states_to_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaling_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mdesired_states_to_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaling_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_desired_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired_states_to_process\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\statemanagers.py\u001b[0m in \u001b[0;36mcompute_desired_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m                     \u001b[0mjoint_timeline_desired_regionalized_entities_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_regionalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                     \u001b[0mjoint_timeline_desired_regionalized_entities_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstate_regionalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjoint_timeline_desired_regionalized_entities_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\entity_state\\entities_states_reg.py\u001b[0m in \u001b[0;36m__add__\u001b[1;34m(self, other_regionalized_states)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 other_regionalized_states : 'EntitiesStatesRegionalized'):\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother_regionalized_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     def __sub__(self,\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\entity_state\\entities_states_reg.py\u001b[0m in \u001b[0;36m_add\u001b[1;34m(self, other_regionalized_states, sign)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother_regionalized_states_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msign\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\entity_state\\entities_states_reg.py\u001b[0m in \u001b[0;36madd_state\u001b[1;34m(self, region_name, entities_state, sign)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entities_states_per_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mentities_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0msign\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entities_states_per_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mentities_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\entity_state\\entities_state.py\u001b[0m in \u001b[0;36m__add__\u001b[1;34m(self, entities_state_or_delta)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 entities_state_or_delta):\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities_state_or_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     def __sub__(self,\n",
      "\u001b[1;32mD:\\AutoscalingSim\\autoscaling-simulator\\autoscalingsim\\utils\\state\\entity_state\\entities_state.py\u001b[0m in \u001b[0;36m_add\u001b[1;34m(self, entities_state_or_delta, sign)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities_state_or_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEntitiesState\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_group_to_add\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities_state_or_delta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mentity_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentities_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0msign\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EntitiesState' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from autoscalingsim import simulator\n",
    "import pandas as pd\n",
    "\n",
    "starting_time = pd.Timestamp(\"2020-09-17T10:00:00\")\n",
    "simulation_step = pd.Timedelta(10, unit = 'ms')\n",
    "time_to_simulate_days = 0.005\n",
    "config_dir = \"experiments/test\"\n",
    "results_dir = None\n",
    "\n",
    "simulator = simulator.Simulator(simulation_step,\n",
    "                                starting_time,\n",
    "                                time_to_simulate_days)\n",
    "\n",
    "simulator.add_simulation(config_dir,\n",
    "                         results_dir)\n",
    "\n",
    "simulator.start_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3\n",
      "2: 2\n",
      "3: 1\n",
      "4: 2\n",
      "6: 1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-26fac31a0f79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter([1, 1, 2, 3, 4, 1, 2, 4, 6])\n",
    "for elem, count in counter.items():\n",
    "    print(\"{}: {}\".format(elem, count))\n",
    "    \n",
    "dd = collections.defaultdict(list)\n",
    "dd[1].append(1)\n",
    "dd\n",
    "\n",
    "Point = collections.namedtuple('Point', {'x', 'y'})\n",
    "r = Point(1 ,20)\n",
    "r.x\n",
    "\n",
    "a = (item for item in range(5))\n",
    "for item in a:\n",
    "    print(item)\n",
    "    \n",
    "def gen():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    \n",
    "g = gen()\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "x = pd.DataFrame({'datetime': [1,2,3], 'value': [4, 5, 6]}).set_index('datetime')\n",
    "x1 = pd.DataFrame(columns = [x.index.name] + x.columns.to_list()).set_index(x.index.name)\n",
    "converted_vals_marked = collections.defaultdict(list)\n",
    "converted_vals_marked.update((k, []) for k in ([x.index.name] + x.columns.to_list()))\n",
    "for ts, row in x.iterrows():\n",
    "    converted_vals = [A(row_elem) for row_elem in row]\n",
    "    for colname, val in zip(x.columns.to_list(), converted_vals):\n",
    "        converted_vals_marked[colname].append(val)\n",
    "    converted_vals_marked[x.index.name].append(ts)\n",
    "\n",
    "xx = pd.DataFrame(converted_vals_marked).set_index(x.index.name)\n",
    "    \n",
    "max(xx['value']).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = dict(a = A(4))\n",
    "isinstance(numbers, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "25\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class A:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        return A(self.x * other)\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        if self.x > other.x:\n",
    "            return self\n",
    "        else:\n",
    "            return other\n",
    "\n",
    "df1 = pd.DataFrame(data = {'index': [1,2,3], 'val': [A(1), A(5), A(13)]})\n",
    "df1 = df1.set_index('index')\n",
    "df2 = df1 * 5\n",
    "\n",
    "for i, r in df2.iterrows():\n",
    "    print(r[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x, y = 0):\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        \n",
    "        return A(self.x + other.x)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return other + self.x\n",
    "        \n",
    "sum([A(2), A(4), A(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class A:\n",
    "    def __init__(self,\n",
    "                 x):\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "    def __deepcopy__(self, memo):\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            setattr(result, k, copy.deepcopy(v, memo))\n",
    "            \n",
    "        return result\n",
    "        \n",
    "a = A(9)\n",
    "b = copy.deepcopy(a)\n",
    "b.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B:\n",
    "    def __init__(self):\n",
    "        self.t = 5\n",
    "\n",
    "class A:\n",
    "    def __init__(self, x):\n",
    "        self._x = x\n",
    "        \n",
    "    def upd(self, x):\n",
    "        t = self\n",
    "        t.x = x\n",
    "        return self.x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return AI(self)\n",
    "\n",
    "class AI:\n",
    "    def __init__(self, a):\n",
    "        self._i = 0\n",
    "        self._a = a\n",
    "        \n",
    "    def __next__(self):\n",
    "        \n",
    "        if self._i < len(self._a._x):\n",
    "            ret = self._a._x[self._i]\n",
    "            self._i += 1\n",
    "            return ret\n",
    "        raise StopIteration\n",
    "    \n",
    "a = A([B(), B()])\n",
    "for aa in a:\n",
    "    aa.t = 6\n",
    "    \n",
    "b = {}.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int.__div__(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_inspect import get_parameters\n",
    "\n",
    "class A:\n",
    "    pass\n",
    "\n",
    "class B:\n",
    "    pass\n",
    "\n",
    "list_of_a = List[A]\n",
    "list_of_b = List[B]\n",
    "\n",
    "class D:\n",
    "    def __init__(self, x):\n",
    "        if x[0].__class__ == A:\n",
    "            self.t = 'A'\n",
    "        elif x[0].__class__ == B:\n",
    "            self.t = 'B'\n",
    "\n",
    "    \n",
    "d = D([A(), A()])\n",
    "d.t\n",
    "#ff = [B(), B()]\n",
    "#get_parameters(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from autoscalingsim.simulation.simulation import Simulation\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "CDF_FILENAME = 'cdf_response_times.png'\n",
    "RESP_TIMES_HIST_FILENAME = 'hist_response_times.png'\n",
    "FULFILLED_FAILED_BARS_FILENAME = 'bars_fulfilled_failed.png'\n",
    "\n",
    "TS_LINE_WORKLOAD_FILENAME = 'ts_line_workload.png'\n",
    "TOTAL_REQS_BARS_FILENAME = 'bars_total_gen_reqs.png'\n",
    "TS_LINE_NODES_FILENAME = 'ts_line_nodes.png'\n",
    "BUF_WAIT_TIME_HIST_FILENAME = 'hist_buf_waiting_time.png'\n",
    "REQ_TIMES_DISTR_BARS_FILENAME = 'bars_req_time_distribution_by_cat.png'\n",
    "\n",
    "MAX_PLOTS_CNT_ROW = 4\n",
    "\n",
    "class AnalysisFramework:\n",
    "    \"\"\"\n",
    "    Combines the functionality to build the figures based on the simulation\n",
    "    results. The following figures are supported:\n",
    "        - Autoscaling quality evaluation category:\n",
    "            + CDF of the response times, all the request types on the same plot\n",
    "            + Histogram of the response times, separately for each request type\n",
    "            + Barchart of fulfilled requests vs dropped, a bar for each request type\n",
    "            > utilization?\n",
    "        - Autoscaling behaviour characterization category:\n",
    "            + Line graph (x axis - time) of the generated requests count,\n",
    "              all the request types on the same plot\n",
    "            + Barchart of the overall amount of generated requests by type\n",
    "            + Line graph (x axis - time) of the desired/current node count,\n",
    "              separately for each node type\n",
    "            + Histogram of the waiting times in the service buffers,\n",
    "              separately for each buffer (idea - to locate the bottleneck service)\n",
    "            + Barchart of the processing vs waiting vs network time for the fulfilled requests,\n",
    "              a bar for each request type\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 simulation_step_ms,\n",
    "                 figures_dir = None):\n",
    "        \n",
    "        self.simulation_step_ms = simulation_step_ms\n",
    "        self.figures_dir = figures_dir\n",
    "        \n",
    "    def build_figures(self,\n",
    "                      simulation = None,\n",
    "                      results_dir = None,\n",
    "                      figures_dir = None):\n",
    "        # TODO: figure settings from config file?\n",
    "        # TODO: get results from the results_dir, also need to add storing into it\n",
    "        if simulation is None and results_dir is None:\n",
    "            sys.exit('Neither simulation nor results directory is provided, cannot build figures.')\n",
    "        \n",
    "        figures_dir_in_use = self.figures_dir\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figures_dir_in_use = figures_dir\n",
    "            \n",
    "        # Getting the data into the unified representation for processing\n",
    "        # either from the simulation or from the results_dir\n",
    "        response_times_per_request_type = {}\n",
    "        workload_ts_per_request_type = {}\n",
    "        buffer_times_by_request = {}\n",
    "        network_times_by_request = {}\n",
    "        desired_node_count = {}\n",
    "        actual_node_count = {}\n",
    "        if not simulation is None:      \n",
    "            workload_ts_per_request_type = simulation.workload_model.workload\n",
    "            response_times_per_request_type = simulation.application_model.response_times_by_request\n",
    "            buffer_times_by_request = simulation.application_model.buffer_times_by_request\n",
    "            network_times_by_request = simulation.application_model.network_times_by_request\n",
    "            desired_node_count = simulation.application_model.platform_model.compute_desired_node_count(self.simulation_step_ms,\n",
    "                                                                                                         simulation.time_to_simulate_ms)\n",
    "            actual_node_count = simulation.application_model.platform_model.compute_actual_node_count(self.simulation_step_ms,\n",
    "                                                                                                      simulation.time_to_simulate_ms)\n",
    "            \n",
    "        # Building figures with the internal functions\n",
    "        # Autoscaling quality evaluation category\n",
    "        self._resp_times_cdf(response_times_per_request_type,\n",
    "                             figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._resp_times_histogram(response_times_per_request_type,\n",
    "                                   3 * self.simulation_step_ms,\n",
    "                                   figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._fulfilled_dropped_barchart(response_times_per_request_type,\n",
    "                                         workload_ts_per_request_type,\n",
    "                                         figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        # Autoscaling behaviour characterization category\n",
    "        self._workload_line_graph(workload_ts_per_request_type,\n",
    "                                  resolution_ms = 5000,\n",
    "                                  figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._generated_requests_by_type_barchart(workload_ts_per_request_type,\n",
    "                                                  figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._nodes_usage_line_graph(desired_node_count,\n",
    "                                     actual_node_count,\n",
    "                                     figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._waiting_service_buffers_histogram(buffer_times_by_request,\n",
    "                                                bins_size_ms = 3 * self.simulation_step_ms,\n",
    "                                                figures_dir = figures_dir_in_use)\n",
    "        \n",
    "        self._distribution_of_reqs_times_barchart(response_times_per_request_type,\n",
    "                                                  buffer_times_by_request,\n",
    "                                                  network_times_by_request,\n",
    "                                                  figures_dir = figures_dir_in_use)\n",
    "    \n",
    "    def _resp_times_cdf(self,\n",
    "                        response_times_per_request_type,\n",
    "                        figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds CDF of the requests by the response times, separate line for\n",
    "        each request type.\n",
    "        \"\"\"\n",
    "        \n",
    "        max_response_time = max([max(response_times_of_req) for response_times_of_req in response_times_per_request_type.values()])\n",
    "        cdf_xlim = max_response_time + 1 * self.simulation_step_ms + 1\n",
    "        x_axis = range(0, cdf_xlim, self.simulation_step_ms)\n",
    "        \n",
    "        cdfs_per_req_type = {}\n",
    "        for req_type, response_times in response_times_per_request_type.items():\n",
    "            reqs_count_binned = [0] * len(x_axis)\n",
    "            \n",
    "            for response_time in response_times:\n",
    "                reqs_count_binned[response_time // self.simulation_step_ms] += 1\n",
    "            \n",
    "            cdfs_per_req_type[req_type] = np.cumsum(reqs_count_binned) / sum(reqs_count_binned)\n",
    "        \n",
    "        for req_type, cdf_vals in cdfs_per_req_type.items():\n",
    "            plt.plot(x_axis, cdf_vals, label = req_type)\n",
    "        \n",
    "        percentiles = [0.99, 0.95, 0.90, 0.80, 0.50]\n",
    "        font = {'color':  'black',\n",
    "                'weight': 'normal',\n",
    "                'size': 8}\n",
    "        for percentile in percentiles:\n",
    "            plt.hlines(percentile, min(x_axis), max(x_axis),\n",
    "                       colors='k', linestyles='dashed', lw = 0.5)\n",
    "            plt.text(0, percentile + 0.001,\n",
    "                     \"{}th percentile\".format(int(percentile * 100)),\n",
    "                     fontdict = font)\n",
    "        \n",
    "        plt.xlabel('Response time, ms')\n",
    "        plt.legend(loc = \"lower right\")\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, CDF_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.title('CDF of requests by response time')\n",
    "            plt.show()\n",
    "            \n",
    "    def _resp_times_histogram(self,\n",
    "                              response_times_per_request_type,\n",
    "                              bins_size_ms = 10,\n",
    "                              figures_dir = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Builds histogram of requests by the response time.\n",
    "        \"\"\"\n",
    "        max_response_time = max([max(response_times_of_req) for response_times_of_req in response_times_per_request_type.values()])\n",
    "        bins_cnt = math.ceil(max_response_time / bins_size_ms)\n",
    "        \n",
    "        plots_count = len(response_times_per_request_type)\n",
    "        rows_cnt = 1\n",
    "        cols_cnt = plots_count\n",
    "        if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "            rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "        \n",
    "        fig, axs = plt.subplots(rows_cnt, cols_cnt,\n",
    "                                sharey = True, tight_layout = True)\n",
    "        \n",
    "        # Ref: https://stackoverflow.com/questions/6963035/pyplot-axes-labels-for-subplots/36542971#36542971\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        \n",
    "        i = 0\n",
    "        for req_type, response_times in response_times_per_request_type.items():\n",
    "            axs_adapted = axs\n",
    "            \n",
    "            if cols_cnt * rows_cnt > 1:\n",
    "                axs_adapted = axs[i]\n",
    "                i += 1\n",
    "                \n",
    "            axs_adapted.hist(response_times,\n",
    "                             bins = bins_cnt)\n",
    "            axs_adapted.title.set_text(req_type)\n",
    "            \n",
    "\n",
    "        plt.xlabel('Response time, ms')\n",
    "        plt.ylabel('Completed requests')\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, RESP_TIMES_HIST_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of requests by response time', y = 1.05)\n",
    "            plt.show()\n",
    "            \n",
    "    def _fulfilled_dropped_barchart(self,\n",
    "                                    response_times_per_request_type,\n",
    "                                    workload_ts_per_request_type,\n",
    "                                    bar_width = 0.15,\n",
    "                                    figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds a barchart of fulfilled requests vs dropped,\n",
    "        a bar for each request type.\n",
    "        \"\"\"\n",
    "        \n",
    "        req_types = list(workload_ts_per_request_type.keys())\n",
    "        succeeded_reqs = []\n",
    "        failed_reqs = []\n",
    "        max_req_cnt = 0\n",
    "        for req_type, workload_timeline in workload_ts_per_request_type.items():\n",
    "            responses_cnt = 0\n",
    "            if req_type in response_times_per_request_type:\n",
    "                responses_cnt = len(response_times_per_request_type[req_type])\n",
    "            \n",
    "            succeeded_reqs.append(responses_cnt)\n",
    "            \n",
    "            requests_cnt = 0\n",
    "            for _, cnt in workload_timeline:\n",
    "                requests_cnt += cnt\n",
    "                \n",
    "            failed_reqs_cnt = requests_cnt - responses_cnt\n",
    "            failed_reqs.append(failed_reqs_cnt)\n",
    "            \n",
    "            max_req_cnt = max([max_req_cnt, requests_cnt])\n",
    "                \n",
    "        plt.bar(req_types, succeeded_reqs,\n",
    "                bar_width, label='Fulfilled')\n",
    "        plt.bar(req_types, failed_reqs,\n",
    "                bar_width, bottom = succeeded_reqs, label='Failed')\n",
    "\n",
    "        plt.ylabel('Requests count')\n",
    "        plt.ylim(top = int(max_req_cnt * 1.05))\n",
    "        plt.legend()\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, FULFILLED_FAILED_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Fulfilled and failed requests')\n",
    "            plt.show()\n",
    "    \n",
    "    def _workload_line_graph(self,\n",
    "                             workload_ts_per_request_type,\n",
    "                             resolution_ms = 1000,\n",
    "                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Line graph (x axis - time) of the desired/current node count,\n",
    "        separately for each node type\n",
    "        \"\"\"\n",
    "        for req_type, workload_ts_raw in workload_ts_per_request_type.items():\n",
    "            \n",
    "            workload_ts_times_ms = []\n",
    "            workload_ts_req_counts = []\n",
    "            new_frame_start_ms = workload_ts_raw[0][0] + resolution_ms\n",
    "            cur_req_cnt = 0\n",
    "            last_added = False\n",
    "            for workload_obs in workload_ts_raw:\n",
    "                last_added = False\n",
    "                \n",
    "                cur_ts_ms = workload_obs[0]\n",
    "                reqs_cnt = workload_obs[1]\n",
    "                \n",
    "                if cur_ts_ms > new_frame_start_ms:\n",
    "                    workload_ts_times_ms.append(new_frame_start_ms)\n",
    "                    workload_ts_req_counts.append(cur_req_cnt)\n",
    "                    cur_req_cnt = 0\n",
    "                    new_frame_start_ms = cur_ts_ms + resolution_ms\n",
    "                    last_added = True\n",
    "                    \n",
    "                cur_req_cnt += reqs_cnt\n",
    "            \n",
    "            if not last_added:\n",
    "                workload_ts_times_ms.append(new_frame_start_ms)\n",
    "                workload_ts_req_counts.append(cur_req_cnt)\n",
    "                \n",
    "            workload_ts_time = [datetime.fromtimestamp(workload_ts_time_ms // 1000) for workload_ts_time_ms in workload_ts_times_ms]\n",
    "\n",
    "            df_workload = pd.DataFrame(data = {'time': workload_ts_time,\n",
    "                                               'requests': workload_ts_req_counts})\n",
    "            df_workload = df_workload.set_index('time')\n",
    "            plt.plot(df_workload, label = req_type)\n",
    "            \n",
    "            plt.ylabel('Workload, requests per {} s'.format(resolution_ms // 1000))\n",
    "            plt.legend(loc = \"lower right\")\n",
    "            plt.xticks(rotation = 70)\n",
    "            \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TS_LINE_WORKLOAD_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.title('Generated workload over time')\n",
    "            plt.show()\n",
    "    \n",
    "    def _generated_requests_by_type_barchart(self,\n",
    "                                             workload_ts_per_request_type,\n",
    "                                             bar_width = 0.15,\n",
    "                                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Barchart of the overall amount of generated requests by type.\n",
    "        \"\"\"\n",
    "        \n",
    "        req_types = list(workload_ts_per_request_type.keys())\n",
    "        reqs_cnts = {}\n",
    "        max_req_cnt = 0\n",
    "        for req_type, workload_timeline in workload_ts_per_request_type.items():\n",
    "            \n",
    "            requests_cnt = 0\n",
    "            for _, cnt in workload_timeline:\n",
    "                requests_cnt += cnt\n",
    "                \n",
    "            reqs_cnts[req_type] = requests_cnt\n",
    "            \n",
    "            max_req_cnt = max([max_req_cnt, requests_cnt])\n",
    "        \n",
    "        plt.bar(list(reqs_cnts.keys()), list(reqs_cnts.values()),\n",
    "                bar_width)\n",
    "\n",
    "        plt.ylabel('Requests count')\n",
    "        plt.ylim(top = int(max_req_cnt * 1.05))\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TOTAL_REQS_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Total generated requests by type')\n",
    "            plt.show()\n",
    "    \n",
    "    def _nodes_usage_line_graph(self,\n",
    "                                desired_node_count,\n",
    "                                actual_node_count,\n",
    "                                resolution_ms = 5000,\n",
    "                                figures_dir = None):\n",
    "        \"\"\"\n",
    "        Line graph (x axis - time) of the desired/current node count,\n",
    "        separately for each node type\n",
    "        \"\"\"\n",
    "        \n",
    "        node_types = list(desired_node_count.keys())\n",
    "        plots_count = len(node_types)\n",
    "        rows_cnt = 1\n",
    "        cols_cnt = plots_count\n",
    "        if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "            rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "        \n",
    "        fig, axs = plt.subplots(rows_cnt, cols_cnt,\n",
    "                                sharey = True, tight_layout = True)\n",
    "        \n",
    "        # Ref: https://stackoverflow.com/questions/6963035/pyplot-axes-labels-for-subplots/36542971#36542971\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        \n",
    "        for node_type in node_types:\n",
    "            \n",
    "            desired_ts = desired_node_count[node_type]['timestamps']\n",
    "            desired_count = desired_node_count[node_type]['count']\n",
    "            \n",
    "            actual_ts = []\n",
    "            actual_count = []\n",
    "            if node_type in actual_node_count:\n",
    "                actual_ts = actual_node_count[node_type]['timestamps']\n",
    "                actual_count = actual_node_count[node_type]['count']\n",
    "            \n",
    "                \n",
    "            desired_ts_time = [datetime.fromtimestamp(desired_ts_el // 1000) for desired_ts_el in desired_ts]\n",
    "            actual_ts_time = [datetime.fromtimestamp(actual_ts_el // 1000) for actual_ts_el in actual_ts]\n",
    "\n",
    "            df_desired = pd.DataFrame(data = {'time': desired_ts_time,\n",
    "                                              'nodes': desired_count})\n",
    "            df_actual = pd.DataFrame(data = {'time': actual_ts_time,\n",
    "                                             'nodes': actual_count})\n",
    "            df_desired = df_desired.set_index('time')\n",
    "            df_actual = df_actual.set_index('time')\n",
    "            \n",
    "            axs.title.set_text(\"Node type {}\".format(node_type))\n",
    "            axs.plot(df_desired, label = \"Desired count\")\n",
    "            axs.plot(df_actual, label = \"Actual count\")\n",
    "            \n",
    "            fig.canvas.draw()\n",
    "            axs.set_xticklabels([txt.get_text() for txt in axs.get_xticklabels()], rotation = 70)\n",
    "            \n",
    "        plt.ylabel('Nodes')\n",
    "        axs.legend(loc = 'upper right', bbox_to_anchor=(0.9, -0.1), ncol = 2,\n",
    "                   borderaxespad = 4.0)\n",
    "            \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, TS_LINE_NODES_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Desired and actual number of nodes per node type', y = 1.05)\n",
    "            plt.show()\n",
    "    \n",
    "    def _waiting_service_buffers_histogram(self,\n",
    "                                           buffer_times_by_request,\n",
    "                                           bins_size_ms = 10,\n",
    "                                           figures_dir = None):\n",
    "        \"\"\"\n",
    "        Builds a set of histograms for the waiting times in buffers.\n",
    "        \"\"\"\n",
    "        \n",
    "        outer_rows_cnt = len(buffer_times_by_request)\n",
    "        outer_cols_cnt = 1\n",
    "        fig = plt.figure()#figsize=(10, 8))\n",
    "        fig.add_subplot(111, frameon = False)\n",
    "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "        outer = gridspec.GridSpec(outer_rows_cnt, outer_cols_cnt,\n",
    "                                  wspace=0.2, hspace=1.0)\n",
    "        \n",
    "        font = {'color':  'black',\n",
    "                'weight': 'bold',\n",
    "                'size': 12}\n",
    "        \n",
    "        i = 0\n",
    "        for req_type, buffers_waiting_times_raw in buffer_times_by_request.items():\n",
    "            \n",
    "            ax_out = plt.Subplot(fig, outer[i])\n",
    "            ax_out.set_title('Request type {}'.format(req_type),\n",
    "                             y = 1.2,\n",
    "                             fontdict = font)\n",
    "            \n",
    "            ax_out.set_xlabel('Time spent waiting in the buffer, ms')\n",
    "            ax_out.set_ylabel('Waiting requests')\n",
    "            ax_out.xaxis.labelpad = 25\n",
    "            ax_out.yaxis.labelpad = 15\n",
    "            ax_out.set_xticks([])\n",
    "            #ax_out.set_yticks([])\n",
    "            \n",
    "            fig.add_subplot(ax_out)\n",
    "            \n",
    "            buffers_waiting_times = {}\n",
    "            for buffer_waiting_time_raw in buffers_waiting_times_raw:\n",
    "                service_name = list(buffer_waiting_time_raw.keys())[0]\n",
    "                buffer_waiting_time_for_service = list(buffer_waiting_time_raw.values())[0]\n",
    "                \n",
    "                if service_name in buffers_waiting_times:\n",
    "                    buffers_waiting_times[service_name].append(buffer_waiting_time_for_service)\n",
    "                else:\n",
    "                    buffers_waiting_times[service_name] = [buffer_waiting_time_for_service]\n",
    "            \n",
    "            max_waiting_time = max([max(sublist) for sublist in list(buffers_waiting_times.values())])\n",
    "            bins_cnt = math.ceil(max_waiting_time / bins_size_ms)\n",
    "            \n",
    "            plots_count = len(buffers_waiting_times)\n",
    "            rows_cnt = 1\n",
    "            cols_cnt = plots_count\n",
    "            if plots_count > MAX_PLOTS_CNT_ROW:\n",
    "                rows_cnt = math.ceil(plots_count / MAX_PLOTS_CNT_ROW)\n",
    "                \n",
    "            # Plotting for req type\n",
    "            inner = gridspec.GridSpecFromSubplotSpec(rows_cnt,\n",
    "                                                     cols_cnt,\n",
    "                                                     subplot_spec = outer[i],\n",
    "                                                     wspace = 0.5,\n",
    "                                                     hspace = 0.1)\n",
    "            \n",
    "            j = 0\n",
    "            for service_name, service_buffer_waiting_times in buffers_waiting_times.items():\n",
    "                ax = plt.Subplot(fig, inner[j], sharey = ax_out)\n",
    "                \n",
    "                ax.hist(service_buffer_waiting_times,\n",
    "                        bins = bins_cnt)\n",
    "                ax.title.set_text('Buffers of the {} service'.format(service_name))\n",
    "                \n",
    "                \n",
    "                if not ax.is_last_row():\n",
    "                    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "                plt.setp(ax.get_yticklabels(), visible=False)\n",
    "                \n",
    "                fig.add_subplot(ax)              \n",
    "                    \n",
    "                j += 1\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, BUF_WAIT_TIME_HIST_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of requests by buffer waiting time', y = 1.05)\n",
    "            plt.show()\n",
    "            \n",
    "    def _distribution_of_reqs_times_barchart(self,\n",
    "                                             response_times_per_request_type,\n",
    "                                             buffer_times_by_request,\n",
    "                                             network_times_by_request,\n",
    "                                             aggregation_fn = np.mean,\n",
    "                                             bar_width = 0.15,\n",
    "                                             figures_dir = None):\n",
    "        \"\"\"\n",
    "        Barchart of the processing vs waiting vs network time\n",
    "        for the fulfilled requests, a bar for each request type\n",
    "        \"\"\"\n",
    "        if not callable(aggregation_fn):\n",
    "            sys.exit('The aggregation function object is not callable.')\n",
    "        \n",
    "        aggregated_processing_time_per_req_type = []\n",
    "        aggregated_buf_waiting_time_per_req_type = []\n",
    "        aggregated_network_time_per_req_type = []\n",
    "        \n",
    "        req_types = list(response_times_per_request_type.keys())\n",
    "        for req_type in req_types:\n",
    "            \n",
    "            req_type_response_times = response_times_per_request_type[req_type]\n",
    "            \n",
    "            req_type_network_times = [0.0]\n",
    "            if req_type in network_times_by_request:\n",
    "                req_type_network_times = network_times_by_request[req_type]\n",
    "            aggregated_network_time_per_req_type.append(aggregation_fn(req_type_network_times))\n",
    "                \n",
    "            req_type_buf_waiting_times = [0.0]\n",
    "            if req_type in buffer_times_by_request:\n",
    "                req_type_buf_waiting_times = [list(buf_wait_time.values())[0] for buf_wait_time in buffer_times_by_request[req_type]]\n",
    "            aggregated_buf_waiting_time_per_req_type.append(aggregation_fn(req_type_buf_waiting_times))\n",
    "            \n",
    "            agg_proc_time = aggregation_fn(req_type_response_times) - (aggregated_buf_waiting_time_per_req_type[-1] + aggregated_network_time_per_req_type[-1])\n",
    "            aggregated_processing_time_per_req_type.append(agg_proc_time)\n",
    "            \n",
    "        plt.bar(req_types, aggregated_processing_time_per_req_type,\n",
    "                bar_width, label='Processing')\n",
    "        plt.bar(req_types, aggregated_network_time_per_req_type,\n",
    "                bar_width, bottom = aggregated_processing_time_per_req_type,\n",
    "                label='Transferring')\n",
    "        \n",
    "        plt.bar(req_types, aggregated_buf_waiting_time_per_req_type,\n",
    "                bar_width, bottom = np.array(aggregated_processing_time_per_req_type) \\\n",
    "                                    + np.array(aggregated_network_time_per_req_type),\n",
    "                label='Waiting')\n",
    "        \n",
    "        plt.ylabel('Duration, ms')\n",
    "        plt.legend(loc = 'upper right', bbox_to_anchor=(0.9, -0.1), ncol = 3)\n",
    "        \n",
    "        if not figures_dir is None:\n",
    "            figure_path = os.path.join(figures_dir, REQ_TIMES_DISTR_BARS_FILENAME)\n",
    "            plt.savefig(figure_path)\n",
    "        else:\n",
    "            plt.suptitle('Distribution of the request time in the application,\\\n",
    "            \\naggregated with the {} function'.format(aggregation_fn.__name__))\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_framework = AnalysisFramework(simulation_step_ms)\n",
    "analysis_framework.build_figures(simulator.simulations[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .forecasting import *\n",
    "\n",
    "class MetricDescription:\n",
    "    \"\"\"\n",
    "    Stores all the necessary information to create a scaling metric.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 metric_name,\n",
    "                 metric_source_in_entity,\n",
    "                 scaled_aspect_source,\n",
    "                 values_filer,\n",
    "                 values_aggregator,\n",
    "                 target_value,\n",
    "                 stabilizer,\n",
    "                 timing_type,\n",
    "                 forecaster,\n",
    "                 capacity_adaptation_type,\n",
    "                 priority,\n",
    "                 initial_max_limit,\n",
    "                 initial_min_limit,\n",
    "                 initial_entity_representation_in_metric):\n",
    "\n",
    "        self.metric_name = metric_name\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "        self.scaled_aspect_source = scaled_aspect_source\n",
    "        self.values_filter = values_filer\n",
    "        self.values_aggregator = values_aggregator\n",
    "        self.priority = priority\n",
    "        self.target_value = target_value\n",
    "        self.stabilizer = stabilizer\n",
    "        self.timing_type = timing_type\n",
    "        self.forecaster = forecaster\n",
    "        self.capacity_adaptation_type = capacity_adaptation_type\n",
    "\n",
    "        self.initial_max_limit = initial_max_limit\n",
    "        self.initial_min_limit = initial_min_limit\n",
    "        self.initial_entity_representation_in_metric = initial_entity_representation_in_metric\n",
    "\n",
    "    def convert_to_metric(self):\n",
    "\n",
    "        return ScalingMetric(self.metric_name,\n",
    "                             self.metric_source_in_entity,\n",
    "                             self.scaled_aspect_source,\n",
    "                             self.values_filer,\n",
    "                             self.values_aggregator,\n",
    "                             self.target_value,\n",
    "                             self.stabilizer,\n",
    "                             self.timing_type,\n",
    "                             self.forecaster,\n",
    "                             self.capacity_adaptation_type,\n",
    "                             self.priority,\n",
    "                             self.initial_max_limit,\n",
    "                             self.initial_min_limit,\n",
    "                             self.initial_entity_representation_in_metric)\n",
    "\n",
    "class ScalingMetric:\n",
    "    \"\"\"\n",
    "    Abstract description of a metric used to determine by how much should the\n",
    "    associated entity be scaled. For instance, the ScalingMetric could be the\n",
    "    CPU utilization. The associated ScaledEntity that contains the metric\n",
    "    could be the node (= VM).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 metric_name,\n",
    "                 metric_source_in_entity,\n",
    "                 scaled_aspect_source,\n",
    "                 values_filer,\n",
    "                 values_aggregator,\n",
    "                 target_value,\n",
    "                 stabilizer,\n",
    "                 timing_type,\n",
    "                 forecaster,\n",
    "                 capacity_adaptation_type,\n",
    "                 priority,\n",
    "                 max_limit,\n",
    "                 min_limit,\n",
    "                 entity_representation_in_metric):\n",
    "        # Static state\n",
    "\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "        # Information sources for metric-based scaling:\n",
    "        # a property of a particular entity instance (object) that\n",
    "        # stores the metric values.\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "\n",
    "        # source of the current value for the scaled aspect, i.e.\n",
    "        # the characteristic that *may directly be changed* as the\n",
    "        # result of the autoscaling process, e.g. entity instances count,\n",
    "        # entity size in terms of some resource (CPU shares)\n",
    "        self.scaled_aspect_source = scaled_aspect_source\n",
    "\n",
    "        # Metric values preprocessing:\n",
    "        # a filter that takes some of the metrics values depending\n",
    "        # on the criteria in it, e.g. takes only values for last 5 seconds.\n",
    "        # Should be callable.\n",
    "        # TODO: consider filter chains\n",
    "        self.values_filter = values_filer\n",
    "\n",
    "        # an aggregator applicable to the time series metrics values\n",
    "        # -- it aggregates metric values prior to the comparison\n",
    "        # against the target. Should be callable.\n",
    "        # TODO: consider values aggregators chains\n",
    "        self.values_aggregator = values_aggregator\n",
    "\n",
    "        # Scaling determinants:\n",
    "        # integer value that determines the position of the metric in the\n",
    "        # sequence of metrics used to scale the entity; the higher the priority\n",
    "        # the closer is the metric to the beginning of the sequence, e.g. if\n",
    "        # there are metrics CPU with the priority 15 and memory with the priority\n",
    "        # -5, then the sequential aggregation thereof results in first computing\n",
    "        # the scaling action based on the CPU utilization, and then using\n",
    "        # these results as limits for the computation based on memory.\n",
    "        self.priority = priority\n",
    "\n",
    "        # a target value of the metric; comparison of the filtered and\n",
    "        # aggregated value of the metric against the target may\n",
    "        # result in the scaling depending on whether the predicate allows\n",
    "        # this or that scaling action.\n",
    "        self.target_value = target_value\n",
    "\n",
    "        # used to stabilize scaling actions over time, e.g. if the scaling happens\n",
    "        # many times over a short period of time, various start-up and termination\n",
    "        # effects may severely impact the response time latency as well as other metrics\n",
    "        self.stabilizer = stabilizer\n",
    "\n",
    "        # either predictive or reactive; depending on the value\n",
    "        # either the real metric value or its forecast is used.\n",
    "        # The use of the \"predictive\" demands presence of the\n",
    "        # forecaster.\n",
    "        # TODO: forecaster initialization\n",
    "        self.timing_type = timing_type\n",
    "        self.forecaster = MetricForecaster()\n",
    "\n",
    "        # either continuous (for vertical scaling) or discrete (for\n",
    "        # horizontal scaling)\n",
    "        self.capacity_adaptation_type = capacity_adaptation_type\n",
    "\n",
    "        # Dynamic state\n",
    "\n",
    "        # current min-max limits on the post-scaling result for the\n",
    "        # aspect of the scaled entity (count of scaled entities in case of horizontal scaling\n",
    "        # or resource limits of scaled entities in case of vertical scaling)\n",
    "        self.limiter = Limiter(min_limit, max_limit)\n",
    "\n",
    "        # current representation of the entity in terms of metric, for instance\n",
    "        # if the entity is the node and the metric is CPU utilization, and the capacity adaptation type is discrete,\n",
    "        # then the representation may be 1 which means that 100 utilization translates\n",
    "        # into 1 node of the given type. This property sits in dynamic category since\n",
    "        # it might get changed during the predictive autoscaling over time with\n",
    "        # new information becoming available about how the entities react on the change\n",
    "        # in metric, e.g. if the metric is the requests per second and the entity is node,\n",
    "        # there is no universal correspondence for every app and every request type.\n",
    "        self.entity_representation_in_metric = entity_representation_in_metric\n",
    "\n",
    "    def compute_desired_state(self):\n",
    "        \"\"\"\n",
    "        Computes the desired state of the associated scaled entity (e.g. service)\n",
    "        according to this particular metric.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extracts available metric values in a form of pandas DataFrame\n",
    "        # with the datetime index. Can be a single value or a sequence of\n",
    "        # values (in this case, some metric history is incorporated)\n",
    "        metric_vals = self.metric_source_in_entity\n",
    "        if self.timing_type == 'predictive':\n",
    "            metric_vals = self.forecaster(cur_metric_vals)\n",
    "        \n",
    "        # Filtering raw metric values (e.g. by removing NA or some\n",
    "        # abnormal values, or by smoothing the signal) and aggregating\n",
    "        # these filtered values to produce the desired aggregated metric,\n",
    "        # e.g. by averaging with the sliding window of a particular length\n",
    "        filtered_metric_vals = self.values_filter(metric_vals)\n",
    "        aggregated_metric_vals = self.values_aggregator(filtered_metric_vals)\n",
    "        \n",
    "        # Computing how does metric value related to the target --\n",
    "        # the assumption is that the closer it is to the target value,\n",
    "        # the better the current state of the application/infrastructure\n",
    "        # reflects the needs of the scaled entity in terms of this metric.\n",
    "        # The computed ratio is used to calaculate the desired amount of the\n",
    "        # scaled aspect (e.g. CPU shares or service instances) by using\n",
    "        # the representation of the metric in terms of the scaled entity and\n",
    "        # the current amount of the scaled entity. Lastly, the computed\n",
    "        # desired amount of the scaled aspect is stabilized to avoid\n",
    "        # oscillations in it that may cause too much overhead when scaling.\n",
    "        metric_ratio = aggregated_metric_vals / self.target_value\n",
    "        desired_scaled_aspect = math.ceil(metric_ratio * self.entity_representation_in_metric * self.scaled_aspect_source)\n",
    "        desired_scaled_aspect_stabilized = self.stabilizer(desired_scaled_aspect)\n",
    "        \n",
    "        # Limiting the produced values of the desired scaled aspect\n",
    "        # such that it stays inside the given band. The limiting\n",
    "        # post-processing is useful if there is a strict limit\n",
    "        # on a particular scaled aspect (e.g. number of VM instances)\n",
    "        # or if the adjustments to the desired scaled aspect must proceed\n",
    "        # in a chained way using different metrics -> min/max limits\n",
    "        # then serve as a communication channel.\n",
    "        desired_scaled_aspect_stabilized_limited = self.limiter(desired_scaled_aspect_stabilized)\n",
    "\n",
    "        return desired_scaled_aspect_stabilized_limited\n",
    "    \n",
    "    def update_limits(self,\n",
    "                      new_min,\n",
    "                      new_max):\n",
    "        \n",
    "        if not limiter is None:\n",
    "            self.limiter.update_limits(new_min,\n",
    "                                       new_max)\n",
    "\n",
    "class MetricForecaster:\n",
    "    \"\"\"\n",
    "    Wraps the supporting forecasting logic that updates the forecasting model\n",
    "    and makes predictions for the defined forecasting horizon. Since the changes\n",
    "    that impact the metric value may occur often, it makes little sense\n",
    "    to forecast for the long term, hence, the extrapolations provided here\n",
    "    are deemed to be very short-sighted. \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 fhorizon_in_steps,\n",
    "                 metric_source_in_entity,\n",
    "                 forecasting_model_name = None,\n",
    "                 forecasting_model_params = None,\n",
    "                 resolution_ms = 10,\n",
    "                 history_data_buffer_size = 10):\n",
    "        \n",
    "        # Static State\n",
    "        self.fhorizon_in_steps = fhorizon_in_steps\n",
    "        self.metric_source_in_entity = metric_source_in_entity\n",
    "        self.resolution_ms = resolution_ms\n",
    "        self.history_data_buffer_size = history_data_buffer_size\n",
    "        \n",
    "        # Dynamic State\n",
    "        if (forecasting_model_name in forecasting_model_registry) and (not forecasting_model_params is None):\n",
    "            self.model = forecasting_model_registry[forecasting_model_name](forecasting_model_params)\n",
    "        else:\n",
    "            self.model = None\n",
    "            \n",
    "        self.history_data_buffer = pd.DataFrame(columns=['value'])\n",
    "\n",
    "    def __call__(self,\n",
    "                 metric_vals):\n",
    "        \n",
    "        \"\"\"\n",
    "        If the forecasting model is not yet fit, then return the metric values\n",
    "        as is by default. Otherwise, the forecast is produced with the existing\n",
    "        model. In any case, an attempt to update the model is performed, in which\n",
    "        at least the historical data is extracted for the accumulation.\n",
    "        \"\"\"\n",
    "        \n",
    "        forecast = metric_vals\n",
    "        if not self.model is None:\n",
    "            forecast = self.model.predict(metric_vals,\n",
    "                                          self.fhorizon_in_steps,\n",
    "                                          self.resolution_ms)\n",
    "            \n",
    "            self._update()\n",
    "        \n",
    "        return forecast\n",
    "        \n",
    "    def _update(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes the available metric values from the self.metric_source_in_entity\n",
    "        until the internal buffer of size self.history_data_buffer_size is full,\n",
    "        then it fits the forecasting model to the collected data. The model is\n",
    "        afterwards updated on each new observation if there was no interrupt in\n",
    "        data acquisition (determined by the timestamps). \n",
    "        \"\"\"\n",
    "        \n",
    "        metric_vals = self.metric_source_in_entity        \n",
    "        self.history_data_buffer = self.history_data_buffer.append(metric_vals)\n",
    "        self.history_data_buffer = self.history_data_buffer.iloc[-self.history_data_buffer_size:,]\n",
    "        if self.history_data_buffer.shape[0] >= self.history_data_buffer_size:\n",
    "            self.model.fit(self.history_data_buffer)\n",
    "                 \n",
    "class Limiter:\n",
    "    \"\"\"\n",
    "    Defines hard and soft limits on the value. Hard limits are set on the\n",
    "    initialization from the configurations and are never changed thereafter.\n",
    "    Soft limits can be updated at any time, e.g. by the desired scaled aspect\n",
    "    values provided by the previous metrics in the chain. Both sets of limits\n",
    "    are applied to the values provided to the limiter on call to it.\n",
    "    \n",
    "    If the soft limits represent a time series, then they have to be applied\n",
    "    to the values that correspond in their timestamps. No alignment logic is\n",
    "    provided -- if the values are somehow misaligned then the min value of\n",
    "    the soft max is used instead of the soft max, and the max value of the\n",
    "    soft min is used instead of soft min.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 init_min,\n",
    "                 init_max):\n",
    "        \n",
    "        self.hard_min = init_min\n",
    "        self.hard_max = init_max\n",
    "        self.soft_min = init_min\n",
    "        self.soft_max = init_max\n",
    "\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        result = self._min_comparison(self.soft_min, values)\n",
    "        result = self._max_comparison(self.soft_max, result)\n",
    "        \n",
    "        result = self._min_comparison(self.hard_min, result)\n",
    "        result = self._max_comparison(self.hard_max, result)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "                \n",
    "    def _min_comparison(self,\n",
    "                        x_min,\n",
    "                        values):\n",
    "        \n",
    "        result = None\n",
    "        if isinstance(x_min, pd.DataFrame):\n",
    "            if (x_min.shape[0] != values.shape[0]) or (np.sum(x_min.index == values.index) < values.shape[0]):\n",
    "                new_min = x_min.max()[0]\n",
    "                result = values[values < new_min].fillna(new_min)\n",
    "            elif (x_min.shape[0] == values.shape[0]) and (np.sum(x_min.index == values.index) == values.shape[0]):\n",
    "                result = values[values < x_min].fillna(x_min)\n",
    "        else:\n",
    "            result = values[values < x_min].fillna(x_min)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def _max_comparison(self,\n",
    "                        x_max,\n",
    "                        values):\n",
    "        \n",
    "        result = None\n",
    "        if isinstance(x_max, pd.DataFrame):\n",
    "            if (x_max.shape[0] != values.shape[0]) or (np.sum(x_max.index == values.index) < values.shape[0]):\n",
    "                new_max = x_max.min()[0]\n",
    "                result = values[values > new_max].fillna(new_max)\n",
    "            elif (x_max.shape[0] == values.shape[0]) and (np.sum(x_max.index == values.index) == values.shape[0]):\n",
    "                result = values[values > x_max].fillna(x_max)\n",
    "        else:\n",
    "            result = values[values > x_max].fillna(x_max)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "                                \n",
    "    def update_limits(self,\n",
    "                      new_min,\n",
    "                      new_max):\n",
    "        \n",
    "        self.soft_min = new_min\n",
    "        self.soft_max = new_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "class ValuesFilter(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An interface for the values filter applied on the preprocessing step\n",
    "    to the raw metrics values.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class DefaultNA(ValuesFilter):\n",
    "    \n",
    "    \"\"\"\n",
    "    Substitutes all the NA values for the default value, e.g. 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'default_value'\n",
    "        if param_key in config:\n",
    "            self.default_value = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} filter.'.format(param_key, self.__class__.__name__))\n",
    "    \n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        return values.fillna(self.default_value)\n",
    "    \n",
    "value_filter_registry = {}\n",
    "value_filter_registry['defaultNA'] = DefaultNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class ValuesAggregator(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An interface to the time window-based aggregator of the metric values.\n",
    "    Basically, it recasts the metric to some particular resolution by\n",
    "    applying the aggregation in the time window, e.g. taking max or avg.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class AvgAggregator(ValuesAggregator):\n",
    "    \n",
    "    \"\"\"\n",
    "    Aggregates the metric time series by computing the average over the\n",
    "    time window of desired resolution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'resolution_window_ms'\n",
    "        if param_key in config:\n",
    "            self.resolution_window_ms = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} aggregator.'.format(param_key, self.__class__.__name__))\n",
    "\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        resolution_delta = self.resolution_window_ms * timedelta(microseconds = 1000)\n",
    "        window_start = values.index[0]\n",
    "        window_end = window_start + resolution_delta\n",
    "     \n",
    "        aggregated_vals = pd.DataFrame(columns=['datetime', 'value'])\n",
    "        aggregated_vals = aggregated_vals.set_index('datetime')\n",
    "        while window_start <= values.index[-1]:\n",
    "            \n",
    "            avg_val = values[(values.index >= window_start) & (values.index < window_end)].mean()[0]\n",
    "            data_to_add = {'datetime': [window_start],\n",
    "                           'value': [avg_val]}\n",
    "            df_to_add = pd.DataFrame(data_to_add)\n",
    "            df_to_add = df_to_add.set_index('datetime')\n",
    "            aggregated_vals = aggregated_vals.append(df_to_add)\n",
    "\n",
    "            window_start = window_end\n",
    "            window_end = window_start + resolution_delta\n",
    "            \n",
    "        return aggregated_vals\n",
    "    \n",
    "value_aggregator_registry = {}\n",
    "value_aggregator_registry['avgAggregator'] = AvgAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class Stabilizer(ABC):\n",
    "    \"\"\"\n",
    "    Defines how the scaled aspect is stabilized, i.e. tries to minimize the\n",
    "    oscillations in the scaled aspect using the windowing.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        pass\n",
    "    \n",
    "class MaxStabilizer(Stabilizer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Stabilizes the oscillations in the scaled aspect by substituting the values\n",
    "    in the time window for the max of the max value encountered in it and of the max\n",
    "    value found in the previous time window. Tends to overprovision the capacity.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        \n",
    "        param_key = 'resolution_window_ms'\n",
    "        if param_key in config:\n",
    "            self.resolution_window_ms = config[param_key]\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the {} stabilizer.'.format(param_key, self.__class__.__name__))\n",
    "    \n",
    "    def __call__(self,\n",
    "                 values):\n",
    "        \n",
    "        resolution_delta = self.resolution_window_ms * timedelta(microseconds = 1000)\n",
    "        window_start = values.index[0]\n",
    "        window_end = window_start + resolution_delta\n",
    "     \n",
    "        stabilized_vals = pd.DataFrame(columns=['datetime', 'value'])\n",
    "        stabilized_vals = stabilized_vals.set_index('datetime')\n",
    "        max_val = values.min()[0]\n",
    "        while window_start <= values.index[-1]:\n",
    "            \n",
    "            selected_vals = values[(values.index >= window_start) & (values.index < window_end)]\n",
    "            max_val = max([selected_vals.max()[0], max_val])\n",
    "            data_to_add = {'datetime': selected_vals.index,\n",
    "                           'value': [max_val] * selected_vals.shape[0]}\n",
    "            df_to_add = pd.DataFrame(data_to_add)\n",
    "            df_to_add = df_to_add.set_index('datetime')\n",
    "            stabilized_vals = stabilized_vals.append(df_to_add)\n",
    "\n",
    "            window_start = window_end\n",
    "            window_end = window_start + resolution_delta\n",
    "            \n",
    "        return stabilized_vals\n",
    "    \n",
    "value_stabilizer_registry = {}\n",
    "value_stabilizer_registry['maxStabilizer'] = MaxStabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class ForecastingModel(ABC):\n",
    "    \"\"\"\n",
    "    Wraps the forecasting model used by MetricForecaster.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 forecasting_model_params):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self,\n",
    "            data):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self,\n",
    "                metric_vals,\n",
    "                fhorizon_in_steps,\n",
    "                resolution_ms):\n",
    "        pass\n",
    "    \n",
    "class SimpleAverage(ForecastingModel):\n",
    "    \n",
    "    \"\"\"\n",
    "    The forecasting model that averages the last averaging_interval observations\n",
    "    and repeats the resulting averaged value as the forecast for the forecasting\n",
    "    horizon.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 forecasting_model_params):\n",
    "        \n",
    "        param_key = 'averaging_interval'\n",
    "        if param_key in forecasting_model_params:\n",
    "            self.averaging_interval = forecasting_model_params['averaging_interval']\n",
    "        else:\n",
    "            raise ValueError('Not found key {} in the parameters of the forecasting model.'.format(param_key))\n",
    "        \n",
    "        self.averaged_value = 0\n",
    "    \n",
    "    def fit(self,\n",
    "            data):\n",
    "        \n",
    "        self.averaged_value = data.mean()[0]\n",
    "    \n",
    "    def predict(self,\n",
    "                metric_vals,\n",
    "                fhorizon_in_steps,\n",
    "                resolution_ms):\n",
    "        \n",
    "        one_ms = timedelta(microseconds=1000)\n",
    "        forecasting_interval_start = df.iloc[-1:,].index[0] + resolution_ms * one_ms\n",
    "        forecasting_interval_end = forecasting_interval_start + fhorizon_in_steps * resolution_ms * one_ms\n",
    "        forecast_interval = pd.date_range(start = forecasting_interval_start,\n",
    "                                          end = forecasting_interval_end,\n",
    "                                          freq = str(resolution_ms) + 'L')\n",
    "        forecasts_df = pd.DataFrame(date_rng, columns=['date'])\n",
    "        forecasts_df['value'] = [self.averaged_value] * len(date_rng)\n",
    "        forecasts_df['datetime'] = pd.to_datetime(forecasts_df['date'])\n",
    "        forecasts_df = forecasts_df.set_index('datetime')\n",
    "        forecasts_df.drop(['date'], axis=1, inplace=True)\n",
    "        \n",
    "        return forecasts_df\n",
    "    \n",
    "forecasting_model_registry = {}\n",
    "forecasting_model_registry['simpleAvg'] = SimpleAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "date_rng = pd.date_range(start='1/1/2018', end='1/02/2018', freq='H')\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['data'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "df.head(15)\n",
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('datetime')\n",
    "df.drop(['date'], axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.DataFrame(columns=['datetime', 'value'])\n",
    "tt = tt.set_index('datetime')\n",
    "data = {'datetime': [df.index[0]],\n",
    "        'value': [99]}\n",
    "t = pd.DataFrame(data)\n",
    "t = t.set_index('datetime')\n",
    "tt = tt.append(t)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "d = timedelta(microseconds=1000)\n",
    "df.iloc[-1:,].index[0] + 1000 * d\n",
    "\n",
    "date_rng = pd.date_range(start=df.iloc[-1:,].index[0] + 1000 * d,\n",
    "                         end=df.iloc[-1:,].index[0] + 10000 * d,\n",
    "                         freq = '1000L')\n",
    "\n",
    "df1 = pd.DataFrame(date_rng, columns=['date'])\n",
    "df1['value'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "df1['datetime'] = pd.to_datetime(df1['date'])\n",
    "df1 = df1.set_index('datetime')\n",
    "df1.drop(['date'], axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fparams = {}\n",
    "fparams['averaging_interval'] = 10\n",
    "mf = MetricForecaster(10,\n",
    "                      df1,\n",
    "                      'simpleAvg',\n",
    "                      fparams,\n",
    "                      1000,\n",
    "                      200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = mf(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = mf(df1)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = mf(df1)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = r.iloc[:50,].append(r1.iloc[50:,])\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr[(rr.index > rr.index[10]) & (rr.index < rr.index[9])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ScalingEffectAggregationRule(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    An aggregation rule for the desired scaling effect values produced\n",
    "    by the metrics for the associated entity.\n",
    "    Two different approaches to aggregation are available:\n",
    "    \n",
    "        Sequential: the desired scaling effect is computed on a metric-by-metric\n",
    "                    basis starting with the metric of the highest priority, then\n",
    "                    the desired scaling effect computed for the previous metric is\n",
    "                    used as limits for the next metric to compute. The scaling\n",
    "                    effect produced by the last metric in the chain is used\n",
    "                    as the final desired scaling effect.\n",
    "                    \n",
    "        Parallel:   the desired scaling effect is computed at once, using the\n",
    "                    desired scaling effects computed by every metric. For instance,\n",
    "                    it can be an average of all the desired scaling effects,\n",
    "                    or the maximum can be taken.\n",
    "                    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        self.metrics_by_priority = metrics_by_priority\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self):\n",
    "        pass\n",
    "    \n",
    "class SequentialScalingEffectAggregationRule(ScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Sequentially calls metrics to produce desired scaling effect values for the\n",
    "    associated entity, each subsequent metric gets the soft limits on the desired\n",
    "    scaling effect values from the previous one (if it is not the first metric\n",
    "    in the sequence).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority,\n",
    "                 expected_deviation_ratio = 0.25):\n",
    "        \n",
    "        super().__init__(metrics_by_priority)\n",
    "        \n",
    "        if expected_deviation_ratio < 0:\n",
    "            raise ValueError('expected_deviation_ratio cannot be negative')\n",
    "        self.expected_deviation_ratio = expected_deviation_ratio\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        ordered_metrics = list(self.metrics_by_priority.values())\n",
    "        if len(ordered_metrics) > 1:\n",
    "            for metric, metric_next in zip(ordered_metrics[:-1], ordered_metrics[1:]):\n",
    "                desired_scaled_aspect = metric()\n",
    "                min_lim = np.floor((1 - self.expected_deviation_ratio) * desired_scaled_aspect)\n",
    "                max_lim = np.ceil((1 + self.expected_deviation_ratio) * desired_scaled_aspect)\n",
    "                metric_next.update_limits(min_lim, max_lim)\n",
    "                \n",
    "        return ordered_metrics[-1]()\n",
    "    \n",
    "class ParallelScalingEffectAggregationRule(ScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calls all the metrics at once and jointly aggregates their results.\n",
    "    Currently empty, but might be extended with some joint logic of the\n",
    "    derived concrete aggregation rules.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority,\n",
    "                 pairwise_operation):\n",
    "        \n",
    "        super().__init__(metrics_by_priority)\n",
    "        if not callable(pairwise_operation):\n",
    "            raise ValueError('pairwise_operation not callable.')\n",
    "        self.pairwise_operation = pairwise_operation\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        ordered_metrics = list(self.metrics_by_priority.values())\n",
    "        desired_scaled_aspect_result = ordered_metrics[0]()\n",
    "        if len(ordered_metrics) > 1:\n",
    "            # Pairwise iterative algorithm to account for possible\n",
    "            # inconsistencies in the time series.\n",
    "            \n",
    "            for metric in ordered_metrics[1:]:\n",
    "                \n",
    "                desired_scaled_aspect_result_new = pd.DataFrame(columns=['datetime', 'value'])\n",
    "                desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.set_index('datetime')\n",
    "                cur_desired_scaled_aspect = metric()\n",
    "                \n",
    "                i = 0\n",
    "                j = 0\n",
    "                while (i < len(desired_scaled_aspect_result.index)) and (j < len(cur_desired_scaled_aspect.index)):\n",
    "                    \n",
    "                    cur_res_index = desired_scaled_aspect_result.index[i]\n",
    "                    cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                    cur_val_1 = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index == cur_index]['value'][0]\n",
    "                    cur_val_2 = desired_scaled_aspect_result[desired_scaled_aspect_result.index == cur_res_index]['value'][0]\n",
    "                    aggregated_val = self.pairwise_operation(cur_val_1, cur_val_2)\n",
    "                    \n",
    "                    # Augments to the non-pairwise case\n",
    "                    while ((j + 1) < len(cur_desired_scaled_aspect.index)) and (cur_desired_scaled_aspect.index[j + 1] <= cur_res_index):\n",
    "                        j += 1\n",
    "                        cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                        cur_val_add = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index == cur_index]['value'][0]\n",
    "                        aggregated_val = self.pairwise_operation(aggregated_val, cur_val_add)\n",
    "                        \n",
    "                    data_to_add = {'datetime': [cur_res_index],\n",
    "                                   'value': [aggregated_val]}\n",
    "                    df_to_add = pd.DataFrame(data_to_add)\n",
    "                    df_to_add = df_to_add.set_index('datetime')\n",
    "                    desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.append(df_to_add)\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                    \n",
    "                # Finalizing with cur_index > cur_res_index / non-pairwise case\n",
    "                if j < len(cur_desired_scaled_aspect.index):\n",
    "                    cur_index = cur_desired_scaled_aspect.index[j]\n",
    "                    df_to_add = cur_desired_scaled_aspect[cur_desired_scaled_aspect.index >= cur_index]\n",
    "                    desired_scaled_aspect_result_new = desired_scaled_aspect_result_new.append(df_to_add)\n",
    "                \n",
    "                desired_scaled_aspect_result = desired_scaled_aspect_result_new\n",
    "                            \n",
    "        return desired_scaled_aspect_result\n",
    "        \n",
    "class MaxScalingEffectAggregationRule(ParallelScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    maxScale - pairwise aggregation by taking the max value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        super().__init__(metrics_by_priority,\n",
    "                         max)\n",
    "        \n",
    "class MinScalingEffectAggregationRule(ParallelScalingEffectAggregationRule):\n",
    "    \n",
    "    \"\"\"\n",
    "    minScale - pairwise aggregation by taking the min value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics_by_priority):\n",
    "        \n",
    "        super().__init__(metrics_by_priority,\n",
    "                         min)\n",
    "        \n",
    "scaling_aggregation_rules_registry = {}\n",
    "scaling_aggregation_rules_registry['seqScale'] = SequentialScalingEffectAggregationRule\n",
    "scaling_aggregation_rules_registry['maxScale'] = MaxScalingEffectAggregationRule\n",
    "scaling_aggregation_rules_registry['minScale'] = MinScalingEffectAggregationRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "class A:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.data\n",
    "    \n",
    "    def update_limits(self, s1, s2):\n",
    "        return\n",
    "    \n",
    "a1 = A(rr)\n",
    "a2 = A(r)\n",
    "\n",
    "mbp = {1: a1, 2: a2}\n",
    "mbp_sorted = collections.OrderedDict(sorted(mbp.items()))\n",
    "agg_rule = MaxScalingEffectAggregationRule(mbp_sorted)\n",
    "agg_rule()\n",
    "\n",
    "agg_rule_1 = SequentialScalingEffectAggregationRule(mbp_sorted)\n",
    "agg_rule_1()\n",
    "# config & integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, next_in_kin):\n",
    "        self.next_in_kin = next_in_kin\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.next_in_kin.hi()\n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(self)\n",
    "        self.name = name\n",
    "        \n",
    "    def hi(self):\n",
    "        print(\"Heyya from {}!\".format(self.name))\n",
    "        \n",
    "b = B(\"Buggy\")\n",
    "b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "class A(ABC):\n",
    "    tttt = 5\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def qq():\n",
    "        return A.tttt\n",
    "    \n",
    "A.qq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.__getattribute__('hi')()\n",
    "A.__getattribute__(A, 'qq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class D(C):\n",
    "    def __init__(self, par):\n",
    "        self._par = par\n",
    "        \n",
    "    @property\n",
    "    def par(self):\n",
    "        return self._par\n",
    "    \n",
    "    @par.setter\n",
    "    def par(self, nv):\n",
    "        self._par = nv\n",
    "        \n",
    "d = D(1)\n",
    "d.par = 3\n",
    "d.par\n",
    "d.__setattr__('par', 4)\n",
    "d.par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_rng = pd.date_range(start='1/1/2018', end='1/08/2018', freq='H')\n",
    "vals = [1] * len(date_rng)\n",
    "dff = pd.DataFrame(data = {'datetime': date_rng, 'val': vals})\n",
    "dff = dff.set_index('datetime')\n",
    "dff\n",
    "ddt = pd.Timedelta(120, unit = 'm')\n",
    "ddt\n",
    "len(dff[dff.index > dff.index[167]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "dd = {dff.index[1]: 12, dff.index[0]: 14}\n",
    "OrderedDict(sorted(dd.items(), key = lambda elem: elem[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "d = {'a': 1, 'b': 3, 't': 0}\n",
    "dd = OrderedDict(reversed(sorted(d.items(), key = lambda x: x[1])))\n",
    "\n",
    "poppy = ['a']\n",
    "poppy.append('c')\n",
    "poppy\n",
    "\n",
    "a = A()\n",
    "b = A()\n",
    "c = A()\n",
    "\n",
    "ttt = [a, b, c]\n",
    "print(ttt)\n",
    "ttt.remove(b)\n",
    "ttt\n",
    "{**{},**{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.copysign(1, -0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "b = {'a': 55, 'b': 9}\n",
    "\n",
    "all(v == 8 for v in a.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
