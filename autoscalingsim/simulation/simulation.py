import os
import pickle
from datetime import datetime
from tqdm import tqdm

from ..application.application_model import ApplicationModel
from ..workload.workload_model import WorkloadModel

class Simulation:
    """
    Manages the high-level simulation process and stores all the simulation-relevant variables.
    Before the time time_to_simulate_ms is reached, each simulation_step_ms milliseconds a new
    simulation step is taken by calling _step method. At each simulations step:
    1) new requests entering the simulation are generated by the workload_model,
    2) the generated requests are added to the application_model,
    3) a simulation step of the application model is taken, which implies taking the corresponding
       simulation steps on its services and links/buffers.
    If the results_dir is provided then the resulting response times for the requests and the
    workload generated per timestamp is stored in a pickle file marked with the application name
    taken from the config file and the date and time of the simulation.
    The progress of the simulation is tracked and presented by the progress bar.

    Properties:

        workload_model:                   the model that is used to generate the workload

        application_model:                the application model that is simulated by calling its step() method

        time_to_simulate_ms (int):        the interval of time that should be simulated, in milliseconds

        simulation_step_ms (int):         the discretion of the simulation. IMPORTANT: in order to apporach the
                                          asynchronous behaviour of the real applications as close as possible
                                          this parameter should be as small as possible. Meaningful numbers for
                                          this parameters are around 10-20 ms, smaller ones may result in
                                          very large execution time of the simulation. Ideally, this step should
                                          be not larger than the smallest time required to process any request
                                          on link/in service.

        stat_updates_every_round (int):   every stat_updates_every_round<th> round a stat summary is printed.
                                          If equals 0 then only the progress bar is available, which makes
                                          impossible to observe the time spent at each stat_updates_every_round
                                          rounds.

        results_dir (string):             a directory used to store the results of the simulation, i.e.
                                          reponse times of individual requests and the time series of the
                                          generated workload. If dir does not exist, it is created.

        ********************************************************************************************************

        cur_simulation_time_ms (int):     current simulation time in milliseconds; on the initialization of the
                                          simulation it is set up to equal simulation_start_datetime converted
                                          to ms. Increments by simulation_step_ms on each simulation step.

        sim_round (int):                  current simulation round.

    Methods:

        start:                            main simulation loop which continues until the simulation runs
                                          out of time, i.e. cur_simulation_time_ms > time_to_simulate_ms.

        _step:                            a private simulation step method that should only be called
                                          inside the start method.

    """

    def __init__(self,
                 workload_model : WorkloadModel,
                 application_model : ApplicationModel,
                 simulation_start : pd.Timestamp,
                 time_to_simulate_days : float = 0.0005,
                 simulation_step : pd.Timedelta = pd.Timedelta(10, unit = 'ms'),
                 stat_updates_every_round : int = 0,
                 results_dir : str = None):

        # Static state
        self.workload_model = workload_model
        self.application_model = application_model
        self.simulation_end = simulation_start + pd.Timedelta(time_to_simulate_days, unit = 'd')
        self.simulation_step = simulation_step
        self.stat_updates_every_round = stat_updates_every_round
        self.results_dir = results_dir

        # Dynamic state
        self.cur_simulation_time = simulation_start
        self.sim_round = 0

    def start(self):

        left_to_simulate = self.simulation_end - self.cur_simulation_time
        left_to_simulate_steps = left_to_simulate // self.simulation_step

        with tqdm(total = left_to_simulate_steps) as progress_bar:
            while self.cur_simulation_time <= self.simulation_end:
                self.cur_simulation_time += self.simulation_step
                self._step()
                self.sim_round += 1
                if self.stat_updates_every_round > 0:
                    if self.sim_round % self.stat_updates_every_round == 0:
                        left_to_simulate = self.simulation_end - self.cur_simulation_time
                        left_to_simulate_steps = left_to_simulate // self.simulation_step
                        print('[{}] Left to simulate: {} min or {} steps'.format(str(pd.Timestamp.now()),
                                                                                 str(left_to_simulate),
                                                                                 left_to_simulate_steps))
                progress_bar.update(1)

        # Storing the simulation results on a disk
        if not self.results_dir is None:
            filename = self.application_model.name + "DT" + datetime.now().strftime("%Y-%m-%dT%H-%M-%S") + ".pkl"
            if not os.path.exists(self.results_dir):
                os.mkdir(self.results_dir)
                full_filename = os.path.join(results_dir, filename)

                results_to_store = {'workload_regionalized': self.workload_model.get_generated_workload(),
                                    'response_times_regionalized': self.application_model.workload_stats.get_response_times_by_request(),
                                    'buffer_times_regionalized': self.application_model.workload_stats.get_buffer_times_by_request(),
                                    'network_times_regionalized': self.application_model.workload_stats.get_network_times_by_request(),
                                    'desired_node_count_regionalized': self.application_model.platform_model.compute_desired_node_count(self.simulation_step,
                                                                                                                                        self.simulation_end),
                                    'actual_node_count_regionalized': self.application_model.platform_model.compute_actual_node_count(self.simulation_step,
                                                                                                                                      self.simulation_end)}

                with open(full_filename, 'wb') as f:
                    pickle.dump(results_to_store, f)

    def _step(self):
        new_requests = self.workload_model.generate_requests(self.cur_simulation_time)
        self.application_model.enter_requests(new_requests)
        self.application_model.step(self.cur_simulation_time,
                                    self.simulation_step)
